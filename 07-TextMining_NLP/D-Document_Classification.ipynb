{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Text: Supervised Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lesson, we will focus on how to build our first automatic classification algorithms. Since the topic is huge, we will be simply scratching the surface, to get something working. For those interested in learning more, taking the Data Mining course next semester is the natural sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is the task of choosing the correct class label for a given input. In basic classification tasks, each input is considered in isolation from all other inputs, and the set of labels is defined in advance. Some examples of classification tasks are:\n",
    "\n",
    "* Deciding whether an email is spam or not.\n",
    "* Deciding what the topic of a news article is, from a fixed list of topic areas such as \"sports,\" \"technology,\" and \"politics.\"\n",
    "* Deciding whether a given occurrence of the word bank is used to refer to a river bank, a financial institution, the act of tilting to the side, or the act of depositing something in a financial institution.\n",
    "\n",
    "A classifier is called supervised if it is built based on **training data** containing the correct label for each input. \n",
    "\n",
    "<img src=\"http://www.nltk.org/images/supervised-classification.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common classification task is to classify documents into categories. Let's use for this the Movie Reviews corpus from NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "categories = movie_reviews.categories()\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate the list of files, each with its corresponding category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_files = []\n",
    "for category in categories:\n",
    "    labeled_files += [(fileid, category) for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('neg/cv000_29416.txt', 'neg'),\n",
       " ('neg/cv001_19502.txt', 'neg'),\n",
       " ('neg/cv002_17424.txt', 'neg'),\n",
       " ('neg/cv003_12683.txt', 'neg'),\n",
       " ('neg/cv004_12641.txt', 'neg')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pos/cv995_21821.txt', 'pos'),\n",
       " ('pos/cv996_11592.txt', 'pos'),\n",
       " ('pos/cv997_5046.txt', 'pos'),\n",
       " ('pos/cv998_14111.txt', 'pos'),\n",
       " ('pos/cv999_13106.txt', 'pos')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_files[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([l for l in labeled_files if l[1]=='pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([l for l in labeled_files if l[1]=='neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurizing a Document\n",
    "\n",
    "Now let's create the features. We will create **one feature per word**, with a **binary value**, indicating whether the document contains the word or not. To limit the number of features that the classifier needs to process, we begin by constructing a list of the 2000 most frequent words in the overall corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the words from all the reviews\n",
    "all_words = []\n",
    "for (fileid, category) in labeled_files:\n",
    "    # Get the words of the document\n",
    "    all_words.extend(movie_reviews.words(fileid))\n",
    "\n",
    "# Keep only words that are not stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "filtered = [w.lower() for w in all_words if w.isalpha() and w not in stopwords]\n",
    "    \n",
    "# Compute the word frequency after removing stopwords \n",
    "fdist  = nltk.FreqDist(filtered)\n",
    "features = set([w for (w,f) in fdist.most_common(2000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(fileid):\n",
    "    # Get the words of the document\n",
    "    document_words = set(movie_reviews.words(fileid))\n",
    "    document_features = {}\n",
    "    for word in features:\n",
    "        # Create a boolean feature that is True when the document contains the word\n",
    "        if word in document_words:\n",
    "            document_features[word] = True\n",
    "        else:\n",
    "            document_features[word] = False\n",
    "    return document_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how long it takes to featurize a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.28 ms ± 1.87 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit  document_features(\"pos/cv995_21821.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to visualize how a \"featurized\" document looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>academy</th>\n",
       "      <th>accent</th>\n",
       "      <th>accept</th>\n",
       "      <th>accident</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>acted</th>\n",
       "      <th>...</th>\n",
       "      <th>x</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability   able  absolutely  academy  accent  accept  accident  across  \\\n",
       "0    False  False       False    False   False   False     False   False   \n",
       "1    False   True       False    False   False   False     False   False   \n",
       "\n",
       "     act  acted  ...        x   yeah  year  years    yes    yet   york  young  \\\n",
       "0  False  False  ...    False  False  True  False  False  False  False  False   \n",
       "1  False  False  ...    False  False  True  False  False  False  False  False   \n",
       "\n",
       "   younger   zero  \n",
       "0    False  False  \n",
       "1    False  False  \n",
       "\n",
       "[2 rows x 2000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "testdf = pd.DataFrame(\n",
    "    [document_features(\"pos/cv995_21821.txt\"),\n",
    "     document_features(\"neg/cv003_12683.txt\")]\n",
    ")\n",
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_documents = [(document_features(fileid), category) for (fileid, category) in labeled_files]\n",
    "random.shuffle(labeled_documents)\n",
    "train_set, test_set = labeled_documents[100:], labeled_documents[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     10.1 : 1.0\n",
      "                  seagal = True              neg : pos    =      7.4 : 1.0\n",
      "                   mulan = True              pos : neg    =      7.0 : 1.0\n",
      "             wonderfully = True              pos : neg    =      6.8 : 1.0\n",
      "                   damon = True              pos : neg    =      6.3 : 1.0\n",
      "                  wasted = True              neg : pos    =      5.4 : 1.0\n",
      "                    jedi = True              pos : neg    =      5.3 : 1.0\n",
      "              ridiculous = True              neg : pos    =      5.2 : 1.0\n",
      "                  poorly = True              neg : pos    =      5.1 : 1.0\n",
      "                   awful = True              neg : pos    =      5.1 : 1.0\n",
      "                    lame = True              neg : pos    =      4.9 : 1.0\n",
      "                   waste = True              neg : pos    =      4.8 : 1.0\n",
      "                   bland = True              neg : pos    =      4.4 : 1.0\n",
      "                   worst = True              neg : pos    =      4.2 : 1.0\n",
      "                     era = True              pos : neg    =      4.1 : 1.0\n",
      "                  allows = True              pos : neg    =      4.0 : 1.0\n",
      "               laughable = True              neg : pos    =      4.0 : 1.0\n",
      "                 unfunny = True              neg : pos    =      4.0 : 1.0\n",
      "               fantastic = True              pos : neg    =      3.9 : 1.0\n",
      "                  stupid = True              neg : pos    =      3.8 : 1.0\n",
      "                    dull = True              neg : pos    =      3.8 : 1.0\n",
      "               portrayal = True              pos : neg    =      3.7 : 1.0\n",
      "               memorable = True              pos : neg    =      3.7 : 1.0\n",
      "                    anna = True              pos : neg    =      3.7 : 1.0\n",
      "                    mess = True              neg : pos    =      3.6 : 1.0\n",
      "                  superb = True              pos : neg    =      3.6 : 1.0\n",
      "                   julie = True              neg : pos    =      3.5 : 1.0\n",
      "               pointless = True              neg : pos    =      3.5 : 1.0\n",
      "                terrific = True              pos : neg    =      3.4 : 1.0\n",
      "                  ripley = True              pos : neg    =      3.4 : 1.0\n",
      "                  subtle = True              pos : neg    =      3.4 : 1.0\n",
      "                  boring = True              neg : pos    =      3.4 : 1.0\n",
      "                   badly = True              neg : pos    =      3.3 : 1.0\n",
      "               excellent = True              pos : neg    =      3.3 : 1.0\n",
      "                terrible = True              neg : pos    =      3.3 : 1.0\n",
      "                   hanks = True              pos : neg    =      3.3 : 1.0\n",
      "                contrast = True              pos : neg    =      3.2 : 1.0\n",
      "               perfectly = True              pos : neg    =      3.2 : 1.0\n",
      "               portrayed = True              pos : neg    =      3.1 : 1.0\n",
      "                 freedom = True              pos : neg    =      3.1 : 1.0\n",
      "                     eve = True              neg : pos    =      3.1 : 1.0\n",
      "             masterpiece = True              pos : neg    =      3.1 : 1.0\n",
      "                    tony = True              pos : neg    =      3.0 : 1.0\n",
      "                   snake = True              neg : pos    =      3.0 : 1.0\n",
      "                    zero = True              neg : pos    =      2.9 : 1.0\n",
      "                   lucas = True              pos : neg    =      2.9 : 1.0\n",
      "               effective = True              pos : neg    =      2.9 : 1.0\n",
      "                deserves = True              pos : neg    =      2.8 : 1.0\n",
      "                 sandler = True              neg : pos    =      2.8 : 1.0\n",
      "               realistic = True              pos : neg    =      2.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try to come up with ways to improve the classifier that we discussed above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract all the words from all the reviews\n",
    "all_words = []\n",
    "for (fileid, category) in labeled_files:\n",
    "    # Get the words of the document\n",
    "    all_words.extend(movie_reviews.words(fileid))\n",
    "\n",
    "# Keep only words that are not stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "# Extend with a few keywords that are named entities\n",
    "stopwords.extend([\"mulan\", \"seagal\", \"damon\", \"ripley\", \"jedi\", \"hanks\"])\n",
    "filtered = [w.lower() for w in all_words if w.isalpha() and w not in stopwords]\n",
    "    \n",
    "# Compute the word frequency after removing stopwords \n",
    "fdist  = nltk.FreqDist(filtered)\n",
    "features = set([w for (w,f) in fdist.most_common(2000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(fileid):\n",
    "    # Get the words of the document\n",
    "    document_words = set(movie_reviews.words(fileid))\n",
    "    document_features = {}\n",
    "    for word in features:\n",
    "        # Create a boolean feature that is True when the document contains the word\n",
    "        if word in document_words:\n",
    "            document_features[word] = True\n",
    "        else:\n",
    "            document_features[word] = False\n",
    "    return document_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     10.8 : 1.0\n",
      "             wonderfully = True              pos : neg    =      7.5 : 1.0\n",
      "                   flynt = True              pos : neg    =      5.6 : 1.0\n",
      "                   awful = True              neg : pos    =      5.3 : 1.0\n",
      "                  wasted = True              neg : pos    =      5.2 : 1.0\n",
      "                    lame = True              neg : pos    =      5.1 : 1.0\n",
      "                  poorly = True              neg : pos    =      4.8 : 1.0\n",
      "              ridiculous = True              neg : pos    =      4.7 : 1.0\n",
      "                   waste = True              neg : pos    =      4.7 : 1.0\n",
      "                terrific = True              pos : neg    =      4.5 : 1.0\n",
      "               portrayal = True              pos : neg    =      4.5 : 1.0\n",
      "                     era = True              pos : neg    =      4.4 : 1.0\n",
      "                   bland = True              neg : pos    =      4.4 : 1.0\n",
      "               pointless = True              neg : pos    =      4.4 : 1.0\n",
      "               laughable = True              neg : pos    =      4.3 : 1.0\n",
      "                   worst = True              neg : pos    =      4.1 : 1.0\n",
      "               memorable = True              pos : neg    =      4.0 : 1.0\n",
      "                 unfunny = True              neg : pos    =      4.0 : 1.0\n",
      "                  stupid = True              neg : pos    =      4.0 : 1.0\n",
      "                    mess = True              neg : pos    =      4.0 : 1.0\n",
      "                  allows = True              pos : neg    =      3.9 : 1.0\n",
      "                    dull = True              neg : pos    =      3.6 : 1.0\n",
      "                  boring = True              neg : pos    =      3.5 : 1.0\n",
      "               portrayed = True              pos : neg    =      3.5 : 1.0\n",
      "                  superb = True              pos : neg    =      3.4 : 1.0\n",
      "               fantastic = True              pos : neg    =      3.4 : 1.0\n",
      "                 freedom = True              pos : neg    =      3.4 : 1.0\n",
      "                   snake = True              neg : pos    =      3.3 : 1.0\n",
      "                terrible = True              neg : pos    =      3.3 : 1.0\n",
      "                   badly = True              neg : pos    =      3.3 : 1.0\n",
      "                contrast = True              pos : neg    =      3.2 : 1.0\n",
      "                  subtle = True              pos : neg    =      3.2 : 1.0\n",
      "                     eve = True              neg : pos    =      3.2 : 1.0\n",
      "                    zero = True              neg : pos    =      3.1 : 1.0\n",
      "                   julie = True              neg : pos    =      3.1 : 1.0\n",
      "               excellent = True              pos : neg    =      3.1 : 1.0\n",
      "             masterpiece = True              pos : neg    =      3.1 : 1.0\n",
      "               perfectly = True              pos : neg    =      3.0 : 1.0\n",
      "                    anna = True              pos : neg    =      3.0 : 1.0\n",
      "                  period = True              pos : neg    =      3.0 : 1.0\n",
      "                   lucas = True              pos : neg    =      3.0 : 1.0\n",
      "               realistic = True              pos : neg    =      2.9 : 1.0\n",
      "                deserves = True              pos : neg    =      2.9 : 1.0\n",
      "                 sandler = True              neg : pos    =      2.9 : 1.0\n",
      "                   fails = True              neg : pos    =      2.8 : 1.0\n",
      "                   clich = True              neg : pos    =      2.8 : 1.0\n",
      "               effective = True              pos : neg    =      2.8 : 1.0\n",
      "                   flaws = True              pos : neg    =      2.7 : 1.0\n",
      "                    pain = True              pos : neg    =      2.7 : 1.0\n",
      "                   naked = True              neg : pos    =      2.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "labeled_documents = [(document_features(fileid), category) for (fileid, category) in labeled_files]\n",
    "random.shuffle(labeled_documents)\n",
    "train_set, test_set = labeled_documents[100:], labeled_documents[:100]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(\"Accuracy:\", nltk.classify.accuracy(classifier, test_set))\n",
    "classifier.show_most_informative_features(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
