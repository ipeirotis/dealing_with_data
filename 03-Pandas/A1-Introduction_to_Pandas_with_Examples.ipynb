{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A-Introduction_to_Pandas",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeirotis/dealing_with_data/blob/master/03-Pandas/A1-Introduction_to_Pandas_with_Examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fdYUrR2RPLK"
      },
      "source": [
        "# Introduction to Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycUTUOp0RPLL"
      },
      "source": [
        "## Setup and preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the necessary libraries to connect to MySQL and to read Excel files"
      ],
      "metadata": {
        "id": "0p4nxRUUNjqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo pip3 install -U -q PyMySQL sqlalchemy sql_magic xlrd"
      ],
      "metadata": {
        "id": "utQbDZCIrJSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPK-fH_vRPLR"
      },
      "source": [
        "In order to read and process files, we are going to use a very powerful, and widely used Python library, called pandas. So, our next step is to import the pandas library in Python, and a few related libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs9khdOxRPLS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2KzbTtORPLZ"
      },
      "source": [
        "And we type some code to simply change the visual style of the plots. (The code below is optional and not necessary, and for now you do not need to understand what exactly is happening.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZt6cUxCRPLN"
      },
      "source": [
        "# Render our plots with high resolution\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enddmxxDRPLa"
      },
      "source": [
        "# Make the graphs a bit bigger\n",
        "matplotlib.style.use([\"seaborn-talk\", \"seaborn-ticks\", \"seaborn-whitegrid\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou04bj1STXa4"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas offers the ability to read and write from/to many different data types. We read from a MySQL server using SQL in this notebook. \n",
        "\n",
        "Later, we will discuss [more examples](https://github.com/ipeirotis/dealing_with_data/blob/master/03-Pandas/B1-Pandas_Reading_Data.ipynb), showing how to download and read CSV files, Excel files, fixed-width datasets, and even how to read directly tables from web pages. \n",
        "\n",
        "The [official documentation](https://pandas.pydata.org/docs/reference/io.html) has the full list."
      ],
      "metadata": {
        "id": "znhDezG1Twq-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRkwgJ2BRPLl"
      },
      "source": [
        "## Reading data using SQL from a MySQL Server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YF27gS9RPLl"
      },
      "source": [
        "We will use a dataset with [restaurant inspection results in NYC](https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j). The dataset that we are going to use has been cleaned up, normalized, and stored in our MySQL database, under the `doh_restaurants` database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5GO33l5RPLm"
      },
      "source": [
        "import os\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "conn_string = 'mysql+pymysql://{user}:{password}@{host}/{db}?charset=utf8mb4'.format(\n",
        "    host = 'db.ipeirotis.org', \n",
        "    user = 'student',\n",
        "    password = 'dwdstudent2015', \n",
        "    db = 'doh_restaurants',\n",
        "    encoding = 'utf8mb4')\n",
        "\n",
        "mysql_conn = create_engine(conn_string).connect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNsW_56mRPLq"
      },
      "source": [
        "We fetch the results of the query using the `read_sql` command."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This query returns back the restaurants in the DOH database\n",
        "sql = '''\n",
        "\tSELECT R.CAMIS, R.DBA, R.BUILDING, R.STREET, R.ZIPCODE, R.BORO, \n",
        "          R.CUISINE_DESCRIPTION, R.LATITUDE, R.LONGITUDE\n",
        "\t\tFROM doh_restaurants.restaurants R\n",
        "'''\n",
        "restaurants = pd.read_sql(sql, con=mysql_conn)"
      ],
      "metadata": {
        "id": "xlfDX5AtvG58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0_mc9_6RPLq"
      },
      "source": [
        "# This query returns back the results of the inspections of each restaurant\n",
        "sql = '''\n",
        "\tSELECT R.CAMIS, R.DBA, R.ZIPCODE, R.BORO, R.CUISINE_DESCRIPTION,\n",
        "\t\t\t\t I.INSPECTION_DATE, I.INSPECTION_ID, \n",
        "\t\t\t\t I.INSPECTION_TYPE, I.SCORE, I.GRADE\n",
        "\tFROM restaurants R \n",
        "\t\tJOIN inspections I ON I.CAMIS = R.CAMIS\n",
        "'''\n",
        "inspections = pd.read_sql(sql, con=mysql_conn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This query returns back the results and violations captured in the \n",
        "# latest inspection of each restaurant\n",
        "sql = '''\n",
        "  WITH latest_inspection AS (\n",
        "\t\tSELECT CAMIS, MAX(INSPECTION_DATE) AS INSPECTION_DATE FROM inspections\n",
        "\t\tGROUP BY CAMIS\n",
        "\t)\n",
        "\tSELECT R.CAMIS, R.DBA, R.ZIPCODE, R.BORO,\n",
        "          I.INSPECTION_DATE, I.INSPECTION_ID, I.INSPECTION_TYPE, \n",
        "          V.VIOLATION_CODE, I.SCORE, I.GRADE\n",
        "\t\tFROM restaurants R\n",
        "\t\t\tJOIN latest_inspection L ON R.CAMIS = L.CAMIS\n",
        "\t\t\tJOIN inspections I ON I.CAMIS = L.CAMIS AND L.INSPECTION_DATE = I.INSPECTION_DATE\n",
        "\t\t\tJOIN violations V ON I.INSPECTION_ID = V.INSPECTION_ID\n",
        "'''\n",
        "violations = pd.read_sql(sql, con=mysql_conn)"
      ],
      "metadata": {
        "id": "Gbua5h9RFP0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13OxAtwORPLt"
      },
      "source": [
        "When you run your query using Pandas, you get back a kind of object called a DataFrame, which is made up of rows and columns. Let's take a look at how the object looks like:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "restaurants"
      ],
      "metadata": {
        "id": "yi6DLJiJvcH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want the first 6 lines:\n",
        "# restaurants.head(6)"
      ],
      "metadata": {
        "id": "c2GYjPU4GVBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want the last 10 lines:\n",
        "# restaurants.tail(10)"
      ],
      "metadata": {
        "id": "KUCK6lCrGVD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "Inspect the contents of the `inspections` and `violations` dataframes"
      ],
      "metadata": {
        "id": "6a2EWLmLN36D"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHawKZ5fRPLu"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "9kpUkXl-F0bT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZIRsPfkbFRN"
      },
      "source": [
        "# Data Types and Descriptive Statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Types using `.dtypes`"
      ],
      "metadata": {
        "id": "k4Q1lJcRwUtS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-iZUdU_bFRO"
      },
      "source": [
        "We can also check the data types for each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bsnaxMvbFRO"
      },
      "source": [
        "restaurants.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "Get the data types for the \"inspections\" and \"violations\""
      ],
      "metadata": {
        "id": "J6-OqMcHwMN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "d7P0UqlYwFca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Types using `.describe()`"
      ],
      "metadata": {
        "id": "1c8AQ2LGwdEC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "205YdxR7bFRO"
      },
      "source": [
        "We can use the method \"describe()\" to get a quick overview of the data in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgtjukEUbFRO"
      },
      "source": [
        "restaurants.describe(include='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqJxEPXRbFRO"
      },
      "source": [
        "# Same as above, but the .T command transposes the table\n",
        "restaurants.describe(include='all').T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "Analyze the \"inspections\" and \"violations\" dataframes using the `.describe()` command."
      ],
      "metadata": {
        "id": "_TA1_EkwwmVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "Gp-RaDDBvn9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nLcGpcDRPLz"
      },
      "source": [
        "## Descriptive statistics\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AIX3fGLRPL7"
      },
      "source": [
        "### Descriptive Statistics for Numeric Variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_44IGXw4RPL_"
      },
      "source": [
        "#### Basic descriptive statistics for numeric variables\n",
        "\n",
        "Given that SCORE is a numeric variable, we can get more detailed descriptive statistics for the variable using the `.describe()` command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91cmXd7FRPL_"
      },
      "source": [
        "inspections[\"SCORE\"].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfpyQuyGRPMC"
      },
      "source": [
        "And now that SCORE is a numeric variable, we can examine its distribution by using the `hist` command of Pandas, which creates a histogram. (The histogram is lso available as `plot.hist`, or `plot(kind='hist'))`.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qs50xHYRPMC"
      },
      "source": [
        "inspections[\"SCORE\"].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqWLiM1GRPME"
      },
      "source": [
        "By default, the histogram has ~10 bars in out plot. We can change the resolution of the histogram using the `bins` variable. Larger number of `bins` allow for higher resolution, but if we increase the number too much, many bins end up having very few, or no data points. For example, experiment with changing the balue of bins below, and change the value from 50 to something bigger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ham9TxYoRPMF"
      },
      "source": [
        "inspections[\"SCORE\"].hist(bins=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cumulative option allows us to see how many entries have scores below a particular value."
      ],
      "metadata": {
        "id": "t5s4MM5haJzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inspections[\"SCORE\"].hist(bins=140, cumulative=True)"
      ],
      "metadata": {
        "id": "4gxx39ypZd2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6nkNDoORPMK"
      },
      "source": [
        "# A quick exposure to various options of the \"hist\" command\n",
        "inspections[\"SCORE\"].hist(\n",
        "    bins=50,  # use 50 bars\n",
        "    range=(0, 50),  # only consider scores from 0 to 50\n",
        "    density=False,  # show normalized count (density=True), or raw counts (density= False)\n",
        "    figsize=(15, 5),  # controls the size of the plot\n",
        "    alpha=0.8,  # make the plot 20% transparent\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing plot to cumulative\n",
        "inspections[\"SCORE\"].hist(\n",
        "    bins=50,  # use 50 bars\n",
        "    range=(0, 50),  # only consider scores from 0 to 50\n",
        "    density=True,  # show normalized count (density=True), or raw counts (density= False)\n",
        "    cumulative=True, # change the histogram to be cumulative\n",
        "    figsize=(15, 5),  # controls the size of the plot\n",
        "    alpha=0.8,  # make the plot 20% transparent\n",
        ")"
      ],
      "metadata": {
        "id": "Hd4qhiEXZrvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqX3BxknRPMM"
      },
      "source": [
        "#### Kernel Density Estimation (KDE)\n",
        "\n",
        "An alternative to histograms is to use the **kernel density**, which estimates a continuous function, instead of the bucketized counts, which tends to be discontunuous and bumpy. We can access this usind the [`.plot(kind='kde')`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.kde.html) command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDXan_BCRPMN"
      },
      "source": [
        "# This plots the density of a numeric attribute\n",
        "# kde = kernel density estimation\n",
        "inspections[\"SCORE\"].plot(kind=\"kde\", color=\"Black\", xlim=(0, 50), figsize=(15, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHNYw_8YjcyR"
      },
      "source": [
        "#### Extra: Combining plots\n",
        "\n",
        "Just as a quick note, we can actually easily combine plots in Pandas, by saving a plot in a variable, and then passing the parameter `ax = ....` in the new figure that we are creating. That `ax` parameter indicates that we want to plot the new chart on top of the plot specified in the `ax` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdbTISRojJsN"
      },
      "source": [
        "# We save the plot in the variable \"histogram_figure\"\n",
        "histogram_figure = inspections[\"SCORE\"].hist(\n",
        "    bins=50,  # use 50 bars\n",
        "    range=(0, 50),  # x-axis from 0 to 50\n",
        "    density=True,  # show normalized count (density=True), or raw counts (density= False)\n",
        "    figsize=(15, 5),  # controls the size of the plot\n",
        "    alpha=0.8,  # make the plot 20% transparent\n",
        ")\n",
        "\n",
        "# To combine the plots, we pass the ax = histogram_figure parameter\n",
        "inspections[\"SCORE\"].plot(\n",
        "    kind=\"kde\", \n",
        "    color=\"Black\", \n",
        "    xlim=(0, 50), \n",
        "    figsize=(15, 5), \n",
        "    ax=histogram_figure # <<== We plot this figure on top of \"histogram_figure\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extra 2: Plotting Geographical Position"
      ],
      "metadata": {
        "id": "iArMNcjTKJmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "restaurants.plot(\n",
        "    kind = 'scatter',\n",
        "    x = 'LONGITUDE',\n",
        "    y = 'LATITUDE',\n",
        "    # s = 0.25, # keep the size of each dot small\n",
        "    # figsize = (10,10), # resise the figure\n",
        "    # alpha = 0.5 # make dots transparent\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "EnqHKSAKIxxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y -qq  libgeos-dev libproj-dev proj-data proj-bin libgdal-dev libspatialindex-dev \n",
        "!sudo pip install -q -U shapely rtree pygeos\n",
        "!sudo pip install -q geopandas descartes"
      ],
      "metadata": {
        "id": "li1iTlItKPDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "\n",
        "# Dataset from NYC Open Data: https://data.cityofnewyork.us/City-Government/Neighborhood-Tabulation-Areas/cpf4-rkhq\n",
        "df_nyc = gpd.GeoDataFrame.from_file('https://data.cityofnewyork.us/api/geospatial/cpf4-rkhq?method=export&format=Shapefile')\n",
        "\n",
        "df_nyc.plot(\n",
        "    linewidth=0.5,\n",
        "    color='White',\n",
        "    edgecolor='Black',\n",
        "    figsize=(20, 15),\n",
        "    alpha=0.5\n",
        ")"
      ],
      "metadata": {
        "id": "FkpiJtHzKF4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base = df_nyc.plot(\n",
        "    linewidth=0.5,\n",
        "    color='White',\n",
        "    edgecolor='Black',\n",
        "    figsize=(20, 15),\n",
        "    alpha=0.5)\n",
        "\n",
        "restaurants.plot(\n",
        "    kind = 'scatter',\n",
        "    x = 'LONGITUDE',\n",
        "    y = 'LATITUDE',\n",
        "    s = 1, # keep the size of each dot small\n",
        "    # figsize = (10,10), # resise the figure\n",
        "    alpha = 0.5, # make dots transparent\n",
        "    ax = base\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "RxPaPUbaKmlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vcYE-MURPMP"
      },
      "source": [
        "### Descriptive Statistics for Dates\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr13GaTubFRV"
      },
      "source": [
        "inspections[\"INSPECTION_DATE\"].describe(datetime_is_numeric=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JJJB4dERPMd"
      },
      "source": [
        "#### Exercise\n",
        "\n",
        "* Plot a histogram for `INSPECTION_DATE`. What do you see?\n",
        "* Try modifying the `bins` parameter. What are the results?\n",
        "* The `range=(start, finish)` command is often useful, when we want to focus on a particular part of the dataset. Try using that for  `INSPECTION DATE` to limit the dates to be between 1/1/2019 and 05/30/2022. In Pandas, to convert a string to a date, we use the command `pd.to_datetime`: For example, to write Jan-1-2019, we write `pd.to_datetime(\"2019-01-01\")`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxRHvWPxRPMm"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8XqYeBbRPMo",
        "solution2": "hidden",
        "solution2_first": true
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds2zDG6xRPMp",
        "solution2": "hidden"
      },
      "source": [
        "# Not very appealing\n",
        "inspections[\"INSPECTION_DATE\"].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpwgv7vVRPMr",
        "solution2": "hidden"
      },
      "source": [
        "inspections[\"INSPECTION_DATE\"].hist(bins=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcBGiZ0pRPMt",
        "solution2": "hidden"
      },
      "source": [
        "x_start = pd.to_datetime(\"2019-01-01\")\n",
        "x_end = pd.to_datetime(\"2022-05-31\")\n",
        "bins = (x_end - x_start) / np.timedelta64(1, \"W\")  # being fancy; one bin per week\n",
        "\n",
        "inspections[\"INSPECTION_DATE\"].hist(\n",
        "    range=(\n",
        "        x_start,\n",
        "        x_end,\n",
        "    ),  # limit the range of dates, ignore the 1/1/1990 faulty valye\n",
        "    bins=round(bins),  # number of months in the range -- computed manually\n",
        "    figsize=(15, 5),  # resize 15-width, 5-height\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsAgjwRyRPM7"
      },
      "source": [
        "### Descriptive Statistics for Categorical/string columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRaEBS-GRPM7"
      },
      "source": [
        "We can also get quick statistics about the common values that appear in each column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iZZ5ERvRPM8"
      },
      "source": [
        "restaurants[\"DBA\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syGbdu-9RPM-"
      },
      "source": [
        "restaurants[\"CUISINE_DESCRIPTION\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's keep just the top-10\n",
        "restaurants[\"CUISINE_DESCRIPTION\"].value_counts()[:10]"
      ],
      "metadata": {
        "id": "77EL3B1xe-Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzHAljAjRPNA"
      },
      "source": [
        "And we can use the \"plot\" command to plot the resulting histogram. ([More details](http://pandas.pydata.org/pandas-docs/stable/visualization.html))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUlBxouPRPNB"
      },
      "source": [
        "# We use a horizontal bar chart, aka \"barh\", \n",
        "# to make the text labels easier to read\n",
        "restaurants[\"CUISINE_DESCRIPTION\"].value_counts()[:10].plot(kind=\"barh\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAncl0ibRPNF"
      },
      "source": [
        "# We can store the outcome in another variable\n",
        "# For example, we create now a variable \"cuisines\"\n",
        "# to store the common cuisines\n",
        "cuisines = restaurants[\"CUISINE_DESCRIPTION\"].value_counts()\n",
        "cuisines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtJCxPvtRPNY"
      },
      "source": [
        "cuisines[:20].plot(kind=\"barh\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27wAw1epbFRZ"
      },
      "source": [
        "# We can invert the list by starting at element 19 (the 20th element)\n",
        "# and then go to the beginning of the list going backwards (the :-1 at the end)\n",
        "cuisines[19::-1].plot(kind=\"barh\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "62cUrY1bxmaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise\n",
        "\n",
        "Using the \"violations\" dataframe, analyze the `VIOLATION_CODE` attribute and identify the most common violation codes in the data. Create a bar plot as above to show the frequency of the various violations codes.\n",
        "\n",
        "If you are adventurous, issue a query against the database using the `read_sql` command and get the descriptions of the violations from the table `doh_restaurants.violaction_codes`"
      ],
      "metadata": {
        "id": "cO8UxX4yxm6t"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzD-ebpzRPNd"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Solution"
      ],
      "metadata": {
        "id": "cgU_jjaZfdyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "violations[\"VIOLATION_CODE\"].value_counts()[:10].plot(kind='barh')"
      ],
      "metadata": {
        "id": "7wke6j7aghaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "violations[\"VIOLATION_CODE\"].value_counts()[10::-1].plot(kind='barh')"
      ],
      "metadata": {
        "id": "kPwCJicGf35z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codes = pd.read_sql(\"SELECT * FROM violation_codes\", con=mysql_conn)\n",
        "codes"
      ],
      "metadata": {
        "id": "Tx78lY-SffMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAbbMV_qRPNv"
      },
      "source": [
        "#### Exercise\n",
        "\n",
        "* Create a plot showing the number of restaurants across **zipcodes** and **boroughts**. Use the `ZIPCODE` and `BORO` columns and the `value_counts()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5cD2Fj2RPNw"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2owfbywARPN0",
        "solution2": "hidden",
        "solution2_first": true
      },
      "source": [
        "#### Solution "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJQdi6fGRPN0",
        "solution2": "hidden"
      },
      "source": [
        "restaurants[\"ZIPCODE\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurants[\"BORO\"].value_counts()"
      ],
      "metadata": {
        "id": "yha1PhIBHb2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7elS_06RPN6",
        "solution2": "hidden"
      },
      "source": [
        "restaurants[\"BORO\"].value_counts().plot(kind=\"bar\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB52Xwh6RPN-",
        "solution2": "hidden"
      },
      "source": [
        "restaurants[\"BORO\"].value_counts().plot(kind=\"barh\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurants[\"ZIPCODE\"].value_counts()[:20].plot(kind=\"barh\")"
      ],
      "metadata": {
        "id": "vgHGnXcpHhr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPiGPdmXTHrr"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbvxeiqrTKJV"
      },
      "source": [
        "# Basic Data Manipulation Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTKmk7LqRPOC"
      },
      "source": [
        "## Selecting a subset of the columns -- `filter()`\n",
        "\n",
        "In a dataframe, we can specify the column(s) that we want to keep, and get back another dataframe with just the subset of the columns that we want to keep."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdGNyALJRPOD"
      },
      "source": [
        "inspections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoA5JqtFRPOF"
      },
      "source": [
        "inspections.filter( \n",
        "    items = [\"DBA\", \"GRADE\", \"INSPECTION_DATE\"] \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DbB0h26RPON"
      },
      "source": [
        "columns = [\"CAMIS\", \"DBA\", \"GRADE\", \"INSPECTION_DATE\", \"SCORE\"] \n",
        "\n",
        "# Notice the use of \"chain notation\" below\n",
        "# Chain notation means putting parentheses around\n",
        "# the command and then having each operation in its\n",
        "# own line\n",
        "(\n",
        "  inspections\n",
        "  .filter( items = columns )\n",
        "  .head(10)\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNmPSBrJUrfy"
      },
      "source": [
        "We can also use the `like` option to find all the column names that include a certain string. For example, to get all the columns that include the string `DATE`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0skTt0rNRPOP"
      },
      "source": [
        "inspections.filter(\n",
        "    like = 'DATE'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXTR3gaYU3D9"
      },
      "source": [
        "We can expand the functionality and also use regular expressions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE5G-RtCU9NS"
      },
      "source": [
        "restaurants.filter(\n",
        "    regex = r'^C' # all the columns that start with C\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWg63of5xbjY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "Keep the columns \"DBA\", \"SCORE\", \"CUISINE DESCRIPTION\" and \"ZIPCODE\" from the `inspections` dataframe."
      ],
      "metadata": {
        "id": "v0gv_vjt_tKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "Sn1_-Zts_w6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHIvI4svxcJ0"
      },
      "source": [
        "## Renaming Columns -- `rename()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fLRqM4kxf1W"
      },
      "source": [
        "To do the equivalent of `SELECT attr AS alias` in Pandas, we use the `rename` command, and pass a dictionary specifying which columns we want to rename:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSnqzBFwxqnk"
      },
      "source": [
        "restaurants.rename(\n",
        "    columns = {\n",
        "      \"CAMIS\": \"RESTID\",\n",
        "      \"DBA\": \"REST_NAME\",\n",
        "      \"BUILDING\": \"STREET_NUM\",\n",
        "      \"BORO\": \"BOROUGH\"\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcirVVhaRPOR"
      },
      "source": [
        "## Selecting rows -- `query()`\n",
        "\n",
        "To select rows, we can write basic queries using the `query()` command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_u2KIdGXav3"
      },
      "source": [
        "# Find all violations for restaurants with DBA being Starbucks\n",
        "restaurants.query(' DBA == \"STARBUCKS\" ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37-qYFVyRPOT"
      },
      "source": [
        "# Find all violations with code 04L (i.e., \"has mice\")\n",
        "violations.query(' VIOLATION_CODE == \"04L\" ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V106ezm-RPOW"
      },
      "source": [
        "# We can store the result in a dataframe called  has_mice\n",
        "has_mice = violations.query(' VIOLATION_CODE == \"04L\" ')\n",
        "has_mice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieEWvEbZRPOf"
      },
      "source": [
        "# List the most frequent DBA values in the has_mice dataframe\n",
        "has_mice[\"DBA\"].value_counts()[:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For comparison, the most frequent DBA names overall across restaurants\n",
        "restaurants[\"DBA\"].value_counts()[:20]"
      ],
      "metadata": {
        "id": "4uxLzTiWIXN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaIVZ16DRPOn"
      },
      "source": [
        "And we can use more complex conditions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBDoVR50RPOo"
      },
      "source": [
        "has_mice_10012 = (\n",
        "    violations\n",
        "    .query('  VIOLATION_CODE == \"04L\" and ZIPCODE == \"10012\" ')\n",
        "    .filter( items = ['DBA', 'INSPECTION_DATE'] )\n",
        ")\n",
        "\n",
        "has_mice_10012"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...and just to have a bit more fun:"
      ],
      "metadata": {
        "id": "vPB54yQ7Nbez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mice = has_mice[\"DBA\"].value_counts() # all restaurants with mice\n",
        "top_restaurants = restaurants[\"DBA\"].value_counts()[:25] # most popular restaurant names\n",
        "\n",
        "# Now calculate what % of the top restaurant chains had mice\n",
        "# The dropna() removes the restaurants that do not appear in top_restaurants\n",
        "(mice / top_restaurants).dropna() "
      ],
      "metadata": {
        "id": "OL5kbSmVNd3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "The following command reads the table `violation_codes`. In addition to the `04L`, check the violation descriptions for the codes `04K`, `04M`, `04N`, and `04O`. Then create an analysis for the restaurants in the area that have these violations.\n",
        "\n",
        "[This StackOverflow post](https://stackoverflow.com/questions/33990955/combine-pandas-dataframe-query-method-with-isin) explains how to use the `IN` construct with Pandas."
      ],
      "metadata": {
        "id": "4lLxFaoDKcug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codes = pd.read_sql(\"SELECT * FROM doh_restaurants.violation_codes\", con=mysql_conn)"
      ],
      "metadata": {
        "id": "bRU5I1OBKheb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Solution"
      ],
      "metadata": {
        "id": "kvUfl5fDMHPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filthy_near_NYU = (\n",
        "    violations\n",
        "    .query('  VIOLATION_CODE in [\"04K\", \"04L\", \"04M\", \"04N\", \"04O\"]  ' )\n",
        "    .query('  ZIPCODE == \"10012\" ')\n",
        "    .filter( items = ['DBA', 'INSPECTION_DATE'] )\n",
        "    .drop_duplicates()\n",
        ")\n",
        "\n",
        "filthy_near_NYU"
      ],
      "metadata": {
        "id": "3licPH6JMIvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07cNAS0Lcf_y"
      },
      "source": [
        "## Selecting distinct values -- `drop_duplicates()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii2uPjjydLyD"
      },
      "source": [
        "We can do the equivalent of `SELECT DISTINCT` in Pandas by doing the following"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmHYLEwhdMei"
      },
      "source": [
        "(\n",
        "    restaurants\n",
        "    .query(' CUISINE_DESCRIPTION == \"Coffee/Tea\"  and ZIPCODE == \"10012\" ')\n",
        "    .filter( items = ['DBA'])\n",
        "    .drop_duplicates()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eqOEGYXdl6K"
      },
      "source": [
        "## Sorting values -- `sort_values()`\n",
        "\n",
        "And we can do the equivalent of `ORDER BY` by using the `.sort_values()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vImT3bKGdz1_"
      },
      "source": [
        "(\n",
        "    has_mice_10012\n",
        "    .sort_values(\"INSPECTION_DATE\", ascending=False)\n",
        "    .head(15)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa78sxUEeev3"
      },
      "source": [
        "(\n",
        "    has_mice_10012\n",
        "    .sort_values([\"INSPECTION_DATE\",\"DBA\"], ascending=[False,True])\n",
        "    .head(15)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UR7tKEURPOu"
      },
      "source": [
        "## Pivot Tables\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple pivot tables\n",
        "\n",
        "[Pivot tables](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html) is one of the most commonly used exploratory tools, and in Pandas they are extremely flexible. \n",
        "\n",
        "For example, let's try to count the number of restaurants that are inspected every day. "
      ],
      "metadata": {
        "id": "yYkjSgvuqvt3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5m48HZFRPOu"
      },
      "source": [
        "# Count the number of CAMIS values that appear on each date\n",
        "pivot = pd.pivot_table(\n",
        "    data=inspections,\n",
        "    index=\"INSPECTION_DATE\",  # specifies the rows\n",
        "    values=\"CAMIS\",  # specifies the content of the cells\n",
        "    aggfunc=\"count\",  # we ask to count how many different CAMIS values we see\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXbdJgt8RPOy"
      },
      "source": [
        "pivot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw_ySegDRPO0"
      },
      "source": [
        "Now, let's plot this. By default, Pandas considers the \"index\" column to be the x-axis, and plots the rest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcxPgXE6RPO9"
      },
      "source": [
        "pivot.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzK9tjhRPO_"
      },
      "source": [
        "# We keep the last 100 entries and plot\n",
        "pivot.tail(100).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Voat735yRPPZ"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Now let's do an exercise,  instead of counting the number of inspections, we want to compute the average score assigned by the inspectors. Hint: We will need to change the `values` and the `aggfunc` parameters in the `pivot_table` function above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlCG1ciIRPPa"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLgKXET5RPPb",
        "solution2": "hidden",
        "solution2_first": true
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As9qTwYLRPPb",
        "solution2": "hidden"
      },
      "source": [
        "pivot = pd.pivot_table(\n",
        "    data=inspections,\n",
        "    index=\"INSPECTION_DATE\",  # specifies the rows\n",
        "    values=\"SCORE\",  # specifies the content of the cells\n",
        "    aggfunc=\"mean\",  # compute the average SCORE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IidFXaRRPPc",
        "solution2": "hidden"
      },
      "source": [
        "pivot.plot(figsize=(10, 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JUwPHXWGLpiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuzOxstCRPPA"
      },
      "source": [
        "### Changing date granularity \n",
        "\n",
        "We can also use the [resample](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html) command to change the frequency from one day, to, say, 7 days. Then we can compute, say, the average (`mean()`) for these days, or the total number (`sum()`) of inspections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffCg-Jo-RPPB"
      },
      "source": [
        "pivot = pd.pivot_table(\n",
        "    data=inspections,\n",
        "    index=\"INSPECTION_DATE\",  # specifies the rows\n",
        "    values=\"CAMIS\",  # specifies the content of the cells\n",
        "    aggfunc=\"count\",  # we ask to count how many different CAMIS values we see\n",
        ")\n",
        "\n",
        "pivot.resample(\"1W\").sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B5xxo0gRPPC"
      },
      "source": [
        "Now, let's plot this. By default, Pandas considers the \"index\" column to be the x-axis, and plots the rest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDa0KRaqRPPC"
      },
      "source": [
        "# Plot the average number of inspections, over 7-day periods\n",
        "pivot.resample(\"1W\").sum().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4WKhTGLRPPF"
      },
      "source": [
        "# Plot the total number of inspections, over 1-month periods\n",
        "pivot.resample(\"1M\").sum().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_WH-s_DRPPK"
      },
      "source": [
        "plot = pivot.resample(\"7D\").mean().plot()\n",
        "plot.set_xlabel(\"Date of Inspection\")\n",
        "plot.set_ylabel(\"Average Number of Inspections (over a 7-day period)\")\n",
        "plot.set_title(\"Analysis of Number of Inspections over Time\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuhabll3RPPL"
      },
      "source": [
        "### Pivot Table with two (or more) variables)\n",
        "\n",
        "We would like to break down the results by borough, so we add the `column` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x57cwCMARPPM"
      },
      "source": [
        "# Show grades broken down by borough\n",
        "pivot2 = pd.pivot_table(\n",
        "    data=inspections,  #\n",
        "    index=\"GRADE\",\n",
        "    columns=\"BORO\",\n",
        "    values=\"CAMIS\",\n",
        "    aggfunc=\"count\"\n",
        ")\n",
        "pivot2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMpy5ZOYRPPS"
      },
      "source": [
        "# By default, the \"index\" becomes the x-axis and we plot all numeric columns\n",
        "pivot2.plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalization"
      ],
      "metadata": {
        "id": "G7ILoF2jwAXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's say that we want to normalize the values\n",
        "# to account for the different number of inspections\n",
        "# in each borough\n",
        "pivot2.sum()"
      ],
      "metadata": {
        "id": "CBK2AWNAvIVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This command normalizes each column, by dividing with its sum:\n",
        "pivot2 / pivot2.sum()"
      ],
      "metadata": {
        "id": "8-rMTEBrvpvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_by_borough = pivot2 / pivot2.sum()\n",
        "\n",
        "# Percent of inspections per borough with a given grade\n",
        "normalized_by_borough.plot(kind='bar')"
      ],
      "metadata": {
        "id": "B-ZMwlyqvxxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalization and Transpose"
      ],
      "metadata": {
        "id": "iTNXe4lYv90l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This takes the transpose of the dataframe\n",
        "pivot2.T"
      ],
      "metadata": {
        "id": "EilqcAPnycVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the transpose now uses the boroughs as the \"x\" axis\n",
        "pivot2.T.plot(kind='barh')"
      ],
      "metadata": {
        "id": "l2888zb6rOlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variation, \n",
        "pivot2.T.plot(kind='barh', stacked=True)"
      ],
      "metadata": {
        "id": "z191SUr7wnQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_by_borough.T.plot(kind='barh', stacked=True).legend(frameon=True)"
      ],
      "metadata": {
        "id": "0cCgPPlnwNsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Exercise\n",
        "\n",
        "We now want to examine if different cuisines have different inspection scores. Compute the average inspection score by cuisine. Use the `sort_values()` command ([documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html)) to order cuisines by their inspection scores. Analyze further by breaking down the score over inspection dates, and plot."
      ],
      "metadata": {
        "id": "zH7HoWXO9sbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zGzg60Fo9uv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Solution"
      ],
      "metadata": {
        "id": "iOK_LNF-9zkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pivot = pd.pivot_table(\n",
        "    data=inspections,\n",
        "    index=\"INSPECTION_DATE\",  # dates are the rows\n",
        "    columns=\"CUISINE_DESCRIPTION\",  # cuisines are the columns\n",
        "    values=\"SCORE\",  # we analyze the SCORE\n",
        "    aggfunc=\"mean\",  # compute the average SCORE\n",
        ")\n",
        "# Select 3 columns (american, frenchn, chinese), compute the average score for a month\n",
        "# and plot the results\n",
        "pivot[[\"American\", \"French\", \"Chinese\"]].resample(\"1M\").mean().plot(figsize=(10, 4))"
      ],
      "metadata": {
        "id": "5qKvSZ6Z90ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV9NGwc2bUCS"
      },
      "source": [
        "## Defining new columns -- `assign()` and `apply()`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdiZXyXIq4rx"
      },
      "source": [
        "### Using the `assign()` approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlTXmZwqkcSE"
      },
      "source": [
        "The `assign` command applies a function to a dataframe and returns back a new dataframe with the new column(s)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We define functions that take as input a dataframe df\n",
        "# and return back a new column.\n",
        "\n",
        "# This function combines STREET/BUILDING/BORO/ZIPCODE columns into one address\n",
        "#\n",
        "def combine_address(df):\n",
        "  return (df.BUILDING + ' ' + df.STREET + ', ' + df.BORO + ', NY ' + df.ZIPCODE).str.upper()\n",
        "\n",
        "\n",
        "# This function computes the distance (in miles) from NYU,\n",
        "# given the lat/lon of the other location\n",
        "#\n",
        "def distance(df):\n",
        "  NYU_lon = -73.9962293\n",
        "  NYU_lat = 40.7291527\n",
        "  # The calculation below is simply the Pythagorean theorem.\n",
        "  # The normalizing values \"0.0146\" and \"0.0196\"\n",
        "  # are just for converting lat/lon differences to miles\n",
        "  distance = ((df['LATITUDE']-NYU_lat)/0.0146)**2 + ((df['LONGITUDE']-NYU_lon)/0.0196)**2\n",
        "  return np.sqrt(distance)\n",
        "\n"
      ],
      "metadata": {
        "id": "D3NMDMFu6cpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqr1oIJYczP3"
      },
      "source": [
        "# We now use the `assign` function to create two new columns\n",
        "# using the logic in the functions above,\n",
        "(\n",
        "  restaurants\n",
        "  .assign(\n",
        "      distance_from_NYU = distance,\n",
        "      address = combine_address\n",
        "  )\n",
        "  .filter(items = ['DBA','address','distance_from_NYU'])\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ub8-qFWixeb"
      },
      "source": [
        "# And let's eliminate now duplicates and sort by distance\n",
        "(\n",
        "  restaurants\n",
        "  .assign(\n",
        "      distance_from_NYU = distance,\n",
        "      address = combine_address\n",
        "  )\n",
        "  .filter(items = ['DBA','address','distance_from_NYU'])\n",
        "  .query('distance_from_NYU > 0') # eliminates NaN values from distance_from_NYU\n",
        "  .drop_duplicates()\n",
        "  .sort_values('distance_from_NYU')\n",
        "  .head(25)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgr0Yg_3k6qW"
      },
      "source": [
        "### Using the `apply` approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njW0EhjzmyK6"
      },
      "source": [
        "The `apply` function allow the users to pass a function and apply it on every single row or column of a Pandas datarame. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIZ_H-s6db9e"
      },
      "source": [
        "!sudo pip3 install -q -U geopy\n",
        "\n",
        "from geopy import distance\n",
        "\n",
        "# A bit more accurate distance calculation, which returns back\n",
        "# the distance in miles. However, we cannot pass a dataframe\n",
        "# to the function but only individual values\n",
        "def distance_from_NYU_geodesic(row):\n",
        "  NYU_lon = -73.9962293\n",
        "  NYU_lat = 40.7291527\n",
        "  NYU = (NYU_lat, NYU_lon)\n",
        "  rest = (row.LATITUDE, row.LONGITUDE)\n",
        "  #if pd.isnull(row.Latitude) or pd.isnull(row.Longitude):\n",
        "  #  return None\n",
        "  return distance.distance(NYU, rest).miles\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71KKNBOqlBTp"
      },
      "source": [
        "# We now create a smaller version of the dataset with just\n",
        "# the names/address/lon/lat of the restaurants\n",
        "rest_names_locations = (\n",
        "    restaurants\n",
        "    .assign(\n",
        "      address = combine_address\n",
        "    )\n",
        "    .filter(items = ['CAMIS','DBA','address','LONGITUDE', 'LATITUDE'])\n",
        "    .query(' LONGITUDE==LONGITUDE ') # idiomatic expression for saying IS NOT NULL\n",
        "    .query(' LATITUDE==LATITUDE ') # idiomatic expression for saying IS NOT NULL\n",
        "    .drop_duplicates()\n",
        ")\n",
        "\n",
        "rest_names_locations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q0gGzxOpE7x"
      },
      "source": [
        "# We will now apply the function distance_from_NYU_geodesic \n",
        "# to every row of the dataset:\n",
        "rest_names_locations.apply(distance_from_NYU_geodesic, axis='columns')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82MvcB29pG1z"
      },
      "source": [
        "# We will now save the result into a new column\n",
        "rest_names_locations['distance_from_NYU']=rest_names_locations.apply(distance_from_NYU_geodesic, axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6vbuAUfdglf"
      },
      "source": [
        "# Let's see how many restaurants are within half a mile from NYU :)\n",
        "(\n",
        "    rest_names_locations\n",
        "    .query('distance_from_NYU < 0.5')\n",
        "    .sort_values('distance_from_NYU')\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54FqcwHSeUM7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTcny4zSw426"
      },
      "source": [
        "## Aggregation functions -- `agg()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUNvMhwNCWF5"
      },
      "source": [
        "inspections['SCORE'].agg('mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpVaAe2uz8Bk"
      },
      "source": [
        "inspections['SCORE'].agg(['mean','std','count','nunique'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJP_gFvKzCNY"
      },
      "source": [
        "inspections.agg(\n",
        "    {\n",
        "        'SCORE': ['mean','std','count','nunique'],\n",
        "        'CAMIS':  ['nunique','count']\n",
        "     }\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92Gsuibr0Zi1"
      },
      "source": [
        "inspections.agg(\n",
        "        num_scored_violations = ('SCORE', 'count'),\n",
        "        mean_score = ('SCORE', 'mean'),\n",
        "        std_score  = ('SCORE', 'std'),\n",
        "        num_entries = ('CAMIS',  'count'),\n",
        "        num_restaurants = ('CAMIS',  'nunique'),\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDAZWbRxw5JJ"
      },
      "source": [
        "## Calculating aggregates per groups -- `groupby()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtjmJWijDXYU"
      },
      "source": [
        "inspections.groupby('INSPECTION_DATE').agg({'SCORE': 'mean'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSoefDKZEbMp"
      },
      "source": [
        "(\n",
        "  inspections\n",
        "  .groupby('INSPECTION_DATE')\n",
        "  .agg(\n",
        "    score_mean = ('SCORE', 'mean'), # calculate the mean of the score\n",
        "    graded_restaurants = ('CAMIS', 'nunique') # count unique restaurant IDs\n",
        "  )\n",
        "  .tail(20) # show the last 20 lines\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DQIJuYIeNi8"
      },
      "source": [
        "(\n",
        "  inspections\n",
        "  .groupby('INSPECTION_DATE')\n",
        "  .agg(\n",
        "    score_mean = ('SCORE', 'mean'), # calculate the aveage score for the date\n",
        "    graded_restaurants = ('CAMIS', 'nunique') # and the number of restaurants\n",
        "  )\n",
        "  .query('graded_restaurants>10') # keep only days with at least 10 graded restauranta\n",
        "  .filter(items=['score_mean']) # we only want to plot the score\n",
        "  .plot()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "  inspections\n",
        "  .groupby('INSPECTION_DATE')\n",
        "  .agg(\n",
        "    score_mean = ('SCORE', 'mean'), # calculate the aveage score for the date\n",
        "    graded_restaurants = ('CAMIS', 'nunique') # and the number of restaurants\n",
        "  )\n",
        "  .query('graded_restaurants>10') # keep only days with at least 10 graded restauranta\n",
        "  .filter(items=['score_mean']) # we only want to plot the score\n",
        "  .resample('1M').mean() # change the frequency to 1 month, and show avg score per month\n",
        "  .plot(\n",
        "    style='--o', # use a dotted line and circles as markers\n",
        "    linewidth=2, # the line should be 1 pixel wide\n",
        "    markersize=8, # the marker size set to 8\n",
        "  ) \n",
        ")"
      ],
      "metadata": {
        "id": "2RrB4nvsTZJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS8nDH9DRPPW"
      },
      "source": [
        "## Advanced Pivot Tables\n",
        "\n",
        "We can also add multiple attributes in the index and columns. It is also possible to have multiple aggregation functions, and we can even define our own aggregation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX1uJBmsRPPW"
      },
      "source": [
        "# We break down by BORO and GRADE, and also calculate\n",
        "# inspections scores\n",
        "pivot_advanced = pd.pivot_table(\n",
        "    data=violations,  #\n",
        "    index=\"INSPECTION_DATE\",\n",
        "    columns=[\"BORO\", \"GRADE\"],\n",
        "    values=\"SCORE\",\n",
        "    aggfunc=[\"mean\", \"std\"],\n",
        ")\n",
        "\n",
        "# Take the total number of inspections (unique and non-unique)\n",
        "agg = pivot_advanced.resample(\"1M\").mean()\n",
        "\n",
        "# Show the last 5 entries and show the transpose (.T)\n",
        "agg.tail().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv0aU9yQRPPh"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjG4WrB5RPPj",
        "solution2": "hidden"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}