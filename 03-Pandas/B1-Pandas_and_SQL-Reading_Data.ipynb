{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "B1-Pandas_and_SQL-Reading_Data.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeirotis/dealing_with_data/blob/master/03-Pandas/B1-Pandas_and_SQL-Reading_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dGMa27CZOmk"
      },
      "source": [
        "# Using Python/Pandas together with SQL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7llwc__ZOml"
      },
      "source": [
        "!sudo pip3 install -U -q PyMySQL sqlalchemy sql_magic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEfQkwBEZOmq"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make the graphs a bit prettier, and bigger\n",
        "matplotlib.style.use(['seaborn-talk', 'seaborn-ticks', 'seaborn-whitegrid'])\n",
        "plt.rcParams['figure.figsize'] = (15, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arGa9IYEZOmt"
      },
      "source": [
        "## Importing SQL results into DataFrames using read_sql\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK9zQj_dZOmu"
      },
      "source": [
        "\n",
        "The `read_sql` function of Pandas allows us to create a dataframe directly from a SQL query. To execute the query, we first setup the connection to the database using the SQLAlchemy library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGLIUgKqZOmv"
      },
      "source": [
        "from sqlalchemy import create_engine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOP8PUGSZOmz"
      },
      "source": [
        "conn_string_imdb = 'mysql+pymysql://{user}:{password}@{host}:{port}/{db}?charset=utf8'.format(\n",
        "    user='student', \n",
        "    password='dwdstudent2015', \n",
        "    host = 'db.ipeirotis.org', \n",
        "    port=3306, \n",
        "    db='imdb',\n",
        "    encoding = 'utf-8'\n",
        ")\n",
        "engine_imdb = create_engine(conn_string_imdb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2z5pg6cZOm3"
      },
      "source": [
        "Let's start with a simple example. We issue an SQL query, and get back the results loaded in a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_5f8Z4tZOm3"
      },
      "source": [
        "query = '''\n",
        "SELECT * FROM actors LIMIT 10\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCVnpC-uZOm7"
      },
      "source": [
        "df_actors = pd.read_sql(query, con=engine_imdb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfthopVUZOm_"
      },
      "source": [
        "df_actors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoeVIevJZOnC"
      },
      "source": [
        "len(df_actors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTeyXXrcZOnG"
      },
      "source": [
        "## Aggregation Calculations: Pandas or SQL? \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgcbKBO2ZOnH"
      },
      "source": [
        "Now let's work on a slightly more advanced example. We want to analyze the number of movies over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiEi_mPQZOnI"
      },
      "source": [
        "## Basic Option: Fetch all data, analyze in Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRm48WyjZOnI"
      },
      "source": [
        "Let's do the simple thing first. We will fetch all the data from the movies table and then do a pivot table on top. Since we care about efficiency, we will also time the operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OH7lluLZOnJ"
      },
      "source": [
        "%%time\n",
        "query = '''SELECT * FROM movies'''\n",
        "df_basic = pd.read_sql(query, con=engine_imdb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACjJE7XdZOnM"
      },
      "source": [
        "len(df_basic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnO1m7UfZOnQ"
      },
      "source": [
        "So, notice that it takes 2-3 seconds to fetch the data from SQL and create the dataframe, as we need to fetch almost 400K records. \n",
        "\n",
        "Once we have the records, we can then compute a pivot table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K1ES46pZOnQ"
      },
      "source": [
        "%%time\n",
        "# Counting movie IDs returns all the movies within the year\n",
        "# Counting movie ranks returns all the movies that have \n",
        "# a non-empty \"rank\" value (i.e., they have been rated)\n",
        "pivot = df_basic.pivot_table(\n",
        "    index = 'year',\n",
        "    aggfunc = 'count',\n",
        "    values = ['id', 'rating']\n",
        ")\n",
        "# Rename the columns\n",
        "pivot.columns = ['all_movies', 'rated_movies']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2SnPFk8ZOnT"
      },
      "source": [
        "# And let's check a few lines of the table\n",
        "pivot.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPtjtub3ZOnX"
      },
      "source": [
        "And we can then plot the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqYxGNKvZOnY"
      },
      "source": [
        "pivot.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtaTCmyqZOnc"
      },
      "source": [
        "## Better option: Aggregation in SQL, fetch only necessary data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x3q5jG8ZOnc"
      },
      "source": [
        "Now let's push the computation on the SQL server instead, using a GROUP BY and COUNT aggregates in SQL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlLPLViiZOnd"
      },
      "source": [
        "%%time\n",
        "query = '''\n",
        "SELECT year, COUNT(*) AS all_movies, COUNT(rating) AS rated_movies\n",
        "FROM movies \n",
        "GROUP BY year\n",
        "ORDER BY year\n",
        "'''\n",
        "df_movies = pd.read_sql(query, con=engine_imdb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQjfvT0yZOng"
      },
      "source": [
        "len(df_movies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psx7jw2CZOnj"
      },
      "source": [
        "df_movies.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAf2iU3pZOnm"
      },
      "source": [
        "Notice that the same calculation was done in a few (4-5) **milliseconds**. The SQL query that we used earlier it took **seconds** to execute. In fact, the **pivot** table calculation, executed after fetching all the data took longer than executing the GROUPBY/COUNT SQL query and fetching the results.\n",
        "\n",
        "While in this example the difference is negligible, once you deal with datasets that have millions, or tens of millions of rows, the savings become material and significant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnm3nzxRZOnm"
      },
      "source": [
        "### Plotting: The importance of index\n",
        "\n",
        "Let's try to plot the results. In pandas, the simple `plot()` command will use the index as the x-axis, and will plot all the numeric columns, as a line plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arqzhozrZOnn"
      },
      "source": [
        "# The plot() command takes the index (the first \"column\") of the dataframe\n",
        "# and makes that the x-axis.\n",
        "# Then it plots *ALL* the numeric columns as a line\n",
        "df_movies.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGBg7NWZZOnq"
      },
      "source": [
        "We do not want to plot the `year` variable as a line. So, we select just the other two columns and plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ivHPNZwZOnq"
      },
      "source": [
        "# First step: We can eliminate the \"year\" line by selecting \n",
        "# the columns that we want to plot\n",
        "# To select columns, we pass a list of the column names that\n",
        "# we want to keep in square brackets\n",
        "df_movies[ [\"all_movies\", \"rated_movies\"] ].plot() \n",
        "# still the x-axis does not list the year"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMyiM6FfZOnt"
      },
      "source": [
        "A bit better. `year` is not appearing anymore, but we still do not have `year` as the x-axis. \n",
        "\n",
        "To make `year` the x-axis, we need to make it the index of the dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjusivJ2ZOnt"
      },
      "source": [
        "df_movies_2 = df_movies.set_index('year')\n",
        "df_movies_2.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3MYd9QBZOnw"
      },
      "source": [
        "Now the plot has the year as the x-axis, and the labels are proper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN0blBYDZOnw"
      },
      "source": [
        "df_movies_2.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt6irpFJZOnz"
      },
      "source": [
        "### (Optional, but useful) Changing data types: Int vs Datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5xEnINyZOn0"
      },
      "source": [
        "In our index above, the \"year\" variable is an integer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bXoVluRZOn0"
      },
      "source": [
        "df_movies_2.index.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-N0ULRDZOn3"
      },
      "source": [
        "This is mostly fine, but we can leverage the time series processing capabilities of Pandas by converting `year` to a date."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCpvBoL0ZOn4"
      },
      "source": [
        "# We first convert the index into datetime.\n",
        "df_movies_2.index = pd.to_datetime(df_movies_2.index, format='%Y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5U5tDfoZOn7"
      },
      "source": [
        "df_movies_2.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5ImhAc2ZOn-"
      },
      "source": [
        "Now we can do the `resample` the dates in the index. For example, we can compute numbers over decades:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4suH3T0dZOn-"
      },
      "source": [
        "df_movies_2.resample('10Y').sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNAQSyI6ZOoB"
      },
      "source": [
        "## Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSczYAKzZOoC"
      },
      "source": [
        "* Connect to the Facebook database, and use the `MemberSince` variable from the `Profiles` table to plot the growth of Facebook users. Use the following information:\n",
        ">    user='student', \n",
        ">    password='dwdstudent2015', \n",
        ">    host = 'db.ipeirotis.org', \n",
        ">    port=3306, \n",
        ">    db='facebook'\n",
        "* (_Learn something new_) Use the [cumsum()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.cumsum.html) function of Pandas and plot the total number of registered users over time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wQrBTcjZOoC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "solution2": "hidden",
        "solution2_first": true,
        "id": "ZDEMAY0IZOoE"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "solution2": "hidden",
        "id": "a53_VtrUZOoF"
      },
      "source": [
        "conn_string_fb = 'mysql+pymysql://{user}:{password}@{host}:{port}/{db}?charset=utf8'.format(\n",
        "    user='student', \n",
        "    password='dwdstudent2015', \n",
        "    host = 'db.ipeirotis.org', \n",
        "    port=3306, \n",
        "    db='facebook',\n",
        "    encoding = 'utf-8'\n",
        ")\n",
        "engine_fb = create_engine(conn_string_fb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "solution2": "hidden",
        "id": "eZv9226hZOoH"
      },
      "source": [
        "%%time\n",
        "# Naive approach, fetch all the data first\n",
        "query = 'SELECT * FROM Profiles'\n",
        "df = pd.read_sql(query, con=engine_fb)\n",
        "pivot = df.pivot_table(\n",
        "    index='MemberSince',\n",
        "    values='ProfileID',\n",
        "    aggfunc='count'    \n",
        ")\n",
        "# Calculate weekly signups\n",
        "weekly_signups = pivot.resample('1W').sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "solution2": "hidden",
        "id": "P4THeH--ZOoJ"
      },
      "source": [
        "%%time\n",
        "# Push calculations into SQL\n",
        "query = '''\n",
        "  SELECT MemberSince, COUNT(ProfileID) as signups \n",
        "  FROM Profiles \n",
        "  GROUP BY MemberSince \n",
        "  ORDER BY MemberSince\n",
        "'''\n",
        "df = pd.read_sql(query, con=engine_fb)\n",
        "df.set_index(\"MemberSince\", inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiM5jx3qtRGj"
      },
      "source": [
        "df.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "solution2": "hidden",
        "id": "B34Gn145ZOoM"
      },
      "source": [
        "df.cumsum().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "solution2": "hidden",
        "id": "mlzxsEGbZOoL"
      },
      "source": [
        "weekly_signups = df.resample('1W').sum()\n",
        "weekly_signups.plot()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}