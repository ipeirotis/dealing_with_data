{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "NewsAPI.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeirotis/dealing_with_data/blob/master/02-WebAPIs/A2-NewsAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interacting with APIs: Retrieving News Articles with NewsAPI\n",
        "\n",
        "In the world of analytics, accessing and working with external data sources is a fundamental skill. Application Programming Interfaces (APIs) provide a structured way for different software systems to communicate and share information. In a previous session, we introduced the core concepts of APIs and how to make basic requests.\n",
        "\n",
        "In this notebook, we will dive deeper into API interaction by using the **NewsAPI**. We will learn how to:\n",
        "\n",
        "*   Make API calls with specific parameters to filter data, focusing on retrieving relevant business news.\n",
        "*   Process the API's response, which is typically in JSON format.\n",
        "*   Extract relevant information from the response for analytical purposes.\n",
        "*   Structure the retrieved data into a pandas DataFrame for further analysis, such as analyzing headline sentiment or identifying key topics in business news.\n",
        "\n",
        "By the end of this notebook, you will be able to retrieve news articles based on various criteria and prepare the data for analytical tasks relevant to business insights."
      ],
      "metadata": {
        "id": "SRytBkCa9rf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding NewsAPI\n",
        "\n",
        "NewsAPI is a simple, easy-to-use API that returns JSON metadata for headlines and articles from news sources and blogs all over the web. It's a great resource for:\n",
        "\n",
        "*   Gathering news data for analysis.\n",
        "*   Building news aggregation tools.\n",
        "*   Researching trends in news coverage.\n",
        "\n",
        "To use NewsAPI, you will need an API key. If you haven't already, please sign up for a free developer account on their website to get your key."
      ],
      "metadata": {
        "id": "dRQEf8jF90yz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Keys and Security Considerations\n",
        "\n",
        "An API key is a secret token that authenticates your requests to the API. **It is crucial to keep your API key confidential.**\n",
        "\n",
        "**For this educational exercise, we will include the API key directly in the code.** However, in any real-world application or production environment, you should **never** hardcode your API key directly in your script or notebook, especially if it might be shared publicly. Secure methods like environment variables or configuration files should be used instead."
      ],
      "metadata": {
        "id": "JghgjkwI95Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the libraries that we will use in this notebook\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "vMrSShCqEtJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcRk8Vml8W4U"
      },
      "source": [
        "# IMPORTANT: Sign up and get your own key for NewsAPI\n",
        "# When the whole class uses a single key, we often run out of quota\n",
        "\n",
        "news_api_key = 'KEY ON SLACK'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding API Rate Limits\n",
        "\n",
        "Many APIs, including NewsAPI, have rate limits to prevent abuse and ensure fair usage. This means there's a limit to how many requests you can make within a certain timeframe (e.g., per minute or per day).\n",
        "\n",
        "If you exceed the rate limit, your requests might be blocked, and you'll receive an error. It's important to be mindful of these limits, especially when testing or running your code multiple times. The free NewsAPI plan has specific limits on the number of requests and results per request."
      ],
      "metadata": {
        "id": "tOJLam7fByM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetching Data from NewsAPI"
      ],
      "metadata": {
        "id": "t3QUypUC-qmc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbSxyRkS8W4X"
      },
      "source": [
        "endpoint = 'https://newsapi.org/v2/top-headlines'\n",
        "parameters = {\n",
        "    'country' : 'us',\n",
        "    'category' : 'business',\n",
        "    'apiKey' : news_api_key,\n",
        "    'pageSize' : 100\n",
        "}\n",
        "resp = requests.get(endpoint, params=parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Error Handling\n",
        "\n",
        "When making API requests, it's good practice to check if the request was successful before trying to process the data. The `requests` library provides ways to check the status code of the response. A status code of 200 generally indicates a successful request.\n",
        "\n",
        "We can also check the 'status' key in the NewsAPI JSON response itself, which should be 'ok' for a successful call."
      ],
      "metadata": {
        "id": "nnsbklk4CvJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if resp.status_code == 200:\n",
        "    data = resp.json()\n",
        "    if data['status'] == 'ok':\n",
        "        print(\"API request successful!\")\n",
        "        # You can now proceed with processing the data\n",
        "    else:\n",
        "        print(f\"API returned an error status: {data['status']}\")\n",
        "        # Print more details if available in the response\n",
        "else:\n",
        "    print(f\"API request failed with status code: {resp.status_code}\")\n",
        "    print(f\"Response text: {resp.text}\") # Helpful for debugging"
      ],
      "metadata": {
        "id": "bycyn8i0CsbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K9_FSEE8W4Y"
      },
      "source": [
        "data = resp.json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring the API Response"
      ],
      "metadata": {
        "id": "N2WWZ3T7-u5m"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ePdlGqW8W4Y"
      },
      "source": [
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the JSON Response Structure\n",
        "\n",
        "When we make a successful API request to NewsAPI, the response data is returned in JSON format. This JSON object is essentially a dictionary in Python. Let's examine the top-level keys we see:\n",
        "\n",
        "*   `status`: Indicates if the request was successful (e.g., 'ok').\n",
        "*   `totalResults`: The total number of results available based on our query parameters.\n",
        "*   `articles`: This is the most important key for us. Its value is a **list** where each element in the list is a dictionary representing a single news article.\n",
        "\n",
        "Understanding this structure is crucial for navigating and extracting the information we need from the API response."
      ],
      "metadata": {
        "id": "eutTrvUTB9KL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuevLxvY8W4Y"
      },
      "source": [
        "data['status']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P-ocnrf8W4Z"
      },
      "source": [
        "data['totalResults']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is  a list of the returned articles\n",
        "data['articles']"
      ],
      "metadata": {
        "id": "KIYcuPfcL5Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not freak out. It is just a big list.\n",
        "# This is the first article in the list\n",
        "data['articles'][0]"
      ],
      "metadata": {
        "id": "Voou6n1sjwMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise: Adding a Keyword Search\n",
        "\n",
        "The `top-headlines` endpoint of the NewsAPI allows you to search for specific keywords within the headlines and descriptions of articles. This is very useful for narrowing down your search to topics of interest within a category like 'business'.\n",
        "\n",
        "Examine the documentation of the [`top-headlines` endpoint](https://newsapi.org/docs/endpoints/top-headlines) specifically looking for parameters related to keywords.\n",
        "\n",
        "Your task is to:\n",
        "\n",
        "1.  Create a Python function that takes a keyword as input.\n",
        "2.  Inside the function, construct the API request parameters, including the provided keyword.\n",
        "3.  Make the API call using the `requests` library.\n",
        "4.  Process the JSON response.\n",
        "5.  Return the list of articles (the value associated with the 'articles' key) from the response.\n",
        "\n",
        "This function should make it easy to retrieve business headlines related to a specific term, like 'inflation' or 'technology'."
      ],
      "metadata": {
        "id": "ZPEXynSZLtcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "JXOBZI4mLtE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyzing the returned JSON objects that represent the individual articles"
      ],
      "metadata": {
        "id": "PTl_KFgBH_BV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6ksEOAu8W4Z"
      },
      "source": [
        "# This is the first article in the list\n",
        "data['articles'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see the keys for an individual article\n",
        "data['articles'][0].keys()"
      ],
      "metadata": {
        "id": "Bu_ZV8yWIt6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Structure of an Individual Article\n",
        "\n",
        "As we can see, each element in the `data['articles']` list is a Python dictionary. This dictionary contains various pieces of information about the news article, such as:\n",
        "\n",
        "  *   `source`: Information about the news source (another nested dictionary).\n",
        "  *   `author`: The author of the article.\n",
        "  *   `title`: The headline of the article.\n",
        "  *   `description`: A brief summary of the article.\n",
        "  *   `url`: The URL to the full article.\n",
        "  *   `urlToImage`: A URL to an image related to the article.\n",
        "  *   `publishedAt`: The publication date and time.\n",
        "  *   `content`: A truncated version of the article's content (often just the beginning).\n",
        "\n",
        "We will now work with these individual article dictionaries to extract and process the information we need."
      ],
      "metadata": {
        "id": "JUCc3GPeD7rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['articles'][0]['description']"
      ],
      "metadata": {
        "id": "QeBWsq-IF_BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['articles'][0]['content']"
      ],
      "metadata": {
        "id": "2ZAS2HCeHlI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing Article Data\n",
        "\n",
        "### Iterate over all articles and do various things"
      ],
      "metadata": {
        "id": "GHPehBADILNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using `pd.json_normalize`\n",
        "\n",
        "The API response is in JSON format, and the articles are a list of dictionaries. `pd.json_normalize` is a convenient function from the pandas library that can take a list of dictionaries (like our `data['articles']`) and automatically create a DataFrame.\n",
        "\n",
        "One of the key features of `pd.json_normalize` is its ability to **flatten** nested structures within the dictionaries. For instance, if an article had a nested dictionary for 'source' information, `pd.json_normalize` would create separate columns in the DataFrame for the keys within the 'source' dictionary (e.g., 'source.id', 'source.name').\n",
        "\n",
        "This makes it easy to quickly get our article data into a tabular format for initial exploration."
      ],
      "metadata": {
        "id": "-ARpKCMqAOv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# That is a convenient way to create a datafame\n",
        "# from a **list** of **JSON/dictionaries**. A bit awkward\n",
        "# though if we want to work with each individual article\n",
        "\n",
        "df = pd.json_normalize( data['articles'] )\n",
        "df"
      ],
      "metadata": {
        "id": "34QSH9KNIP9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcvkXq768W4a"
      },
      "source": [
        "# Print the titles of the news articles\n",
        "for article in data['articles']:\n",
        "    print(article['title'])\n",
        "    print('-------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Include Article URLs\n",
        "\n",
        "Modify the code above to print also the URL of each article."
      ],
      "metadata": {
        "id": "T-AbBq5_Iczh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "oR9evu1BJEAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "40XP0JMrJh-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Include URL and Title Length\n",
        "\n",
        "Modify the code above to print also the URL of each article, and print the length of the title."
      ],
      "metadata": {
        "id": "-zTUzK5kJidN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IiNMC91ZJI4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oe_tOVvqJqHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structuring Data for a DataFrame\n",
        "\n",
        "While `pd.json_normalize` is quick, sometimes we want to select specific fields or perform transformations before creating the DataFrame. A common approach is to iterate through the API response, create a list of dictionaries where each dictionary represents a row in our desired DataFrame, and then convert this list into a pandas DataFrame."
      ],
      "metadata": {
        "id": "cOUyBg7WAuvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example\n",
        "\n",
        "Create a dataframe using the code above to print also the URL of each article, and print the length of the title. Create a histogram of the title lengths."
      ],
      "metadata": {
        "id": "UVhAkx4UJqck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = [] # We store here our results\n",
        "\n",
        "# We go through all the articles\n",
        "for article in data['articles']:\n",
        "  # Remember that \"article\" is the loop variable\n",
        "\n",
        "  # We create our own dictionaries, with the attributes that we need\n",
        "  entry = {\n",
        "      \"title\": article['title'],\n",
        "      \"url\": article['url'],\n",
        "      \"title_length\": len(article['title']) # Length of the title in characters\n",
        "  }\n",
        "  results.append(entry)\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df"
      ],
      "metadata": {
        "id": "b9wGSCz7Jyen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a histogram of title lengths\n",
        "df['title_length'].hist(figsize=(6,2), bins=20)"
      ],
      "metadata": {
        "id": "rYzOXB2lKLBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create one big string with all the titles\n",
        "titles = '\\n'.join(df['title'])\n",
        "print(titles)"
      ],
      "metadata": {
        "id": "adswqBtUNNa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Get the full text of the news\n",
        "\n",
        "The 'content' field provided by the NewsAPI often contains only a summary or the beginning of the article. To get the full text of the news story, we need to visit the article's URL and extract the content from the webpage itself. This process is often called web scraping.\n",
        "\n",
        "We have a helper function `retrieve_text_from_url` below that uses the `requests` and `BeautifulSoup` libraries to attempt to retrieve and clean the text content from a given URL. Note that extracting clean text from various website structures can be challenging, so this function might not work perfectly for every URL.\n",
        "\n",
        "Your task is to:\n",
        "\n",
        "1.  Iterate through the list of articles (`data['articles']`).\n",
        "2.  For each article, use the `retrieve_text_from_url` function with the article's 'url'.\n",
        "3.  Store the retrieved full text in a new key (e.g., 'url_content') within the dictionary for each article.\n",
        "4.  Create a new pandas DataFrame (`df_content`) from the updated list of dictionaries, including the original article details and the new 'url_content'."
      ],
      "metadata": {
        "id": "Ntu1dnDsJJT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function: This functions gets as input a URL\n",
        "# and returns back the text that appears in that web page\n",
        "def retrieve_text_from_url(url):\n",
        "    \"\"\"Remove html tags from a string\"\"\"\n",
        "    try:\n",
        "      resp = requests.get(url)\n",
        "      soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "      return soup.get_text()\n",
        "    except:\n",
        "      return \"\""
      ],
      "metadata": {
        "id": "6uK9B9glIb4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = [] # We store here our results\n",
        "\n",
        "# We go through all the articles\n",
        "for article in data['articles']:\n",
        "  c = article.get('content', '') # Use .get() for safety in case 'content' is missing\n",
        "\n",
        "  # START CODE\n",
        "  url = article['url']\n",
        "  url_content = ... # YOUR CODE HERE\n",
        "  # END CODE\n",
        "  entry = {\n",
        "      \"title\": article['title'],\n",
        "      \"url\": article['url'],\n",
        "      \"description\": article.get('description', ''),\n",
        "      \"content\": c,\n",
        "      \"url_content\": ... # YOUR CODE HERE\n",
        "  }\n",
        "  results.append(entry)\n",
        "\n",
        "df_content = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "IsvR-pKLFit8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Solution"
      ],
      "metadata": {
        "id": "cjCxyqLaDBwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = [] # We store here our results\n",
        "\n",
        "# We go through all the articles\n",
        "for article in data['articles']:\n",
        "  c = article.get('content', '') # Use .get() for safety in case 'content' is missing\n",
        "\n",
        "  # START CODE\n",
        "  url = article['url']\n",
        "  url_content = retrieve_text_from_url(url)\n",
        "  # END CODE\n",
        "  entry = {\n",
        "      \"title\": article['title'],\n",
        "      \"url\": article['url'],\n",
        "      \"description\": article.get('description', ''), # Use .get()\n",
        "      \"content\": c,\n",
        "      \"url_content\": url_content\n",
        "  }\n",
        "  results.append(entry)\n",
        "\n",
        "df_content = pd.DataFrame(results)\n",
        "display(df_content)"
      ],
      "metadata": {
        "id": "oqNPpKUaEu5y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}