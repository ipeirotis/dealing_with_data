{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "NewsAPI.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeirotis/dealing_with_data/blob/master/02-WebAPIs/A2-NewsAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "vMrSShCqEtJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcRk8Vml8W4U"
      },
      "source": [
        "# Note, sign up and get your own key for NewsAPI\n",
        "\n",
        "news_api_key = 'KEY ON SLACK'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJoMgSIN8W4X"
      },
      "source": [
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbSxyRkS8W4X"
      },
      "source": [
        "endpoint = 'https://newsapi.org/v2/top-headlines'\n",
        "parameters = {\n",
        "    'country' : 'us',\n",
        "    'category' : 'business',\n",
        "    'apiKey' : news_api_key,\n",
        "    'pageSize' : 100\n",
        "}\n",
        "resp = requests.get(endpoint, params=parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K9_FSEE8W4Y"
      },
      "source": [
        "data = resp.json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ePdlGqW8W4Y"
      },
      "source": [
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuevLxvY8W4Y"
      },
      "source": [
        "data['status']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P-ocnrf8W4Z"
      },
      "source": [
        "data['totalResults']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is  a list of the returned articles\n",
        "data['articles']"
      ],
      "metadata": {
        "id": "KIYcuPfcL5Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not freak out. It is just a big list.\n",
        "# This is the first article in the list\n",
        "data['articles'][0]"
      ],
      "metadata": {
        "id": "Voou6n1sjwMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "\n",
        "Examine the documentation of the [`top-headlines` endpoint](https://newsapi.org/docs/endpoints/top-headlines). Add the ability to search for a specific keyword. Make it a function that gets as input the keyword and returns back the articles."
      ],
      "metadata": {
        "id": "ZPEXynSZLtcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "JXOBZI4mLtE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyzing the returned JSON objects that represent the articles"
      ],
      "metadata": {
        "id": "PTl_KFgBH_BV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6ksEOAu8W4Z"
      },
      "source": [
        "# This is the first article in the list\n",
        "data['articles'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see the keys for an individual article\n",
        "data['articles'][0].keys()"
      ],
      "metadata": {
        "id": "Bu_ZV8yWIt6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['articles'][0]['description']"
      ],
      "metadata": {
        "id": "QeBWsq-IF_BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['articles'][0]['content']"
      ],
      "metadata": {
        "id": "2ZAS2HCeHlI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterate over all articles and do various things"
      ],
      "metadata": {
        "id": "GHPehBADILNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# That is a convenient way to create a datafame\n",
        "# from a **list** of **JSON/dictionaries**. A bit awkward\n",
        "# though if we want to work with each individual article\n",
        "\n",
        "df = pd.json_normalize( data['articles'] )\n",
        "df"
      ],
      "metadata": {
        "id": "34QSH9KNIP9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcvkXq768W4a"
      },
      "source": [
        "# Print the titles of the news articles\n",
        "for article in data['articles']:\n",
        "    print(article['title'])\n",
        "    print('-------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "Modify the code above to print also the URL of each article."
      ],
      "metadata": {
        "id": "T-AbBq5_Iczh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "oR9evu1BJEAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "40XP0JMrJh-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "Modify the code above to print also the URL of each article, and print the length of the title."
      ],
      "metadata": {
        "id": "-zTUzK5kJidN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IiNMC91ZJI4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oe_tOVvqJqHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example\n",
        "\n",
        "Create a dataframe  the code above to print also the URL of each article, and print the length of the title. Create a histogram of the title lengths."
      ],
      "metadata": {
        "id": "UVhAkx4UJqck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = [] # We store here our results\n",
        "\n",
        "# We go through all the articles\n",
        "for article in data['articles']:\n",
        "  # Remember that \"article\" is the loop variable\n",
        "\n",
        "  # We create our own dictionaries, with the attributes that we need\n",
        "  entry = {\n",
        "      \"title\": article['title'],\n",
        "      \"url\": article['url'],\n",
        "      \"title_length\": len(article['title']) # Length of the title in characters\n",
        "  }\n",
        "  results.append(entry)\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df"
      ],
      "metadata": {
        "id": "b9wGSCz7Jyen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a histogram of title lengths\n",
        "df['title_length'].hist(figsize=(6,2), bins=20)"
      ],
      "metadata": {
        "id": "rYzOXB2lKLBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create one big string with all the titles\n",
        "titles = '\\n'.join(df['title'])\n",
        "print(titles)"
      ],
      "metadata": {
        "id": "adswqBtUNNa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "We have a helper functions below. Use the `retrieve_text_from_url` to retrieve the actual content of the URL and store in the dataframe."
      ],
      "metadata": {
        "id": "Ntu1dnDsJJT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function: This functions gets as input a URL\n",
        "# and returns back the text that appears in that web page\n",
        "def retrieve_text_from_url(url):\n",
        "    \"\"\"Remove html tags from a string\"\"\"\n",
        "    try:\n",
        "      resp = requests.get(url)\n",
        "      soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "      return soup.get_text()\n",
        "    except:\n",
        "      return \"\""
      ],
      "metadata": {
        "id": "6uK9B9glIb4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = [] # We store here our results\n",
        "\n",
        "# We go through all the\n",
        "for article in data['articles']:\n",
        "  c = article['content']\n",
        "\n",
        "  # START CODE\n",
        "  url_content = ... # YOUR CODE HERE\n",
        "  # END CODE\n",
        "  entry = {\n",
        "      \"title\": article['title'],\n",
        "      \"url\": article['url'],\n",
        "      \"description\": article['description'],\n",
        "      \"content\": article['content'],\n",
        "      \"url_content\": ... # YOUR CODE HERE\n",
        "  }\n",
        "  results.append(entry)\n",
        "\n",
        "df_content = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "IsvR-pKLFit8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercises\n",
        "\n",
        "\n",
        "1. Go through all the results, and detect the language of the returned articles. Store the results in a dataframe.\n",
        "\n",
        "2. Concatenate all titles into one big string.\n",
        "\n",
        "3. Concatenate all descriptions into one big string."
      ],
      "metadata": {
        "id": "Iy9ULxs7DJ3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "oqNPpKUaEu5y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}