{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeirotis/dealing_with_data/blob/master/05-Time_Series/C-ERCOT_using_Prophet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x4Yt46mPB8R"
      },
      "source": [
        "# Analyzing electricity usage from Electric Reliability Council of Texas (ERCOT)\n",
        "\n",
        "ERCOT releases the electricity usage of their grid at http://www.ercot.com/gridinfo/load\n",
        "\n",
        "The archives are at: http://www.ercot.com/gridinfo/load/load_hist\n",
        "\n",
        "ERCOT also publishes their own load forecasts, this is a good baseline for any model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5CZeiaIPB8T"
      },
      "outputs": [],
      "source": [
        "#@title Setup\n",
        "\n",
        "!pip install -U -q PyMySQL sqlalchemy\n",
        "# prophet\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy import text\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from prophet import Prophet\n",
        "from prophet.plot import plot_plotly, plot_components_plotly, plot_cross_validation_metric\n",
        "from prophet.diagnostics import cross_validation, performance_metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6wKvgzv0_MNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plotting Setup\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "# Change the graph defaults\n",
        "plt.rcParams['figure.figsize'] = (8, 3)  # Default figure size of 8x3 inches\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.rcParams['grid.color'] = 'lightgray'\n",
        "plt.rcParams['font.size'] = 10  # Default font size of 12 points\n",
        "plt.rcParams['lines.linewidth'] = 1  # Default line width of 1 points\n",
        "plt.rcParams['lines.markersize'] = 2  # Default marker size of 2 points\n",
        "plt.rcParams['legend.fontsize'] = 10  # Default legend font size of 10 points"
      ],
      "metadata": {
        "id": "41jrPzTQYLLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and plot the data\n"
      ],
      "metadata": {
        "id": "sMIfV993YAxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn_string = 'mysql+pymysql://{user}:{password}@{host}/{db}?charset=utf8mb4'.format(\n",
        "    host = 'db.ipeirotis.org',\n",
        "    user = 'student',\n",
        "    password = 'dwdstudent2015',\n",
        "    db = 'ercot',\n",
        "    encoding = 'utf8mb4')\n",
        "\n",
        "engine = create_engine(conn_string)\n",
        "\n",
        "# This query loads the dataset from the DB into the dataframe\n",
        "with engine.connect() as con:\n",
        "  sql = \"SELECT * FROM ercot.electricity WHERE DATE_TIME < '2023-06-01'\"\n",
        "  df = pd.read_sql(text(sql), con=con)\n",
        "  df = df.set_index('DATE_TIME')"
      ],
      "metadata": {
        "id": "EmH29w6f8yOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Q5S30e4P9NCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot(\n",
        "    logy=True,\n",
        "    title='ERCOT Consumption Data',\n",
        "    ylabel=\"Consumption\"\n",
        ")\n",
        "plt.legend(bbox_to_anchor=(1, 1), loc='upper left') # move the legend out of the chart"
      ],
      "metadata": {
        "id": "iGDr3BZQ9KV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot(\n",
        "    y = 'ERCOT',\n",
        "    title='ERCOT Consumption Data',\n",
        "    ylabel=\"Consumption\"\n",
        ")"
      ],
      "metadata": {
        "id": "CLHTQf4AB-Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyzing the time series using Prophet\n",
        "\n",
        "For full and current documentation [please check the webpage of the project](https://facebook.github.io/prophet/)."
      ],
      "metadata": {
        "id": "WJAH1lzGpFhd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fZynETNCrKku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can remove the resampling part and use hourly data\n",
        "# but it takes ~10 mins on Colab to process the time series\n",
        "# with hourly data. The tradeoff of working with daily data\n",
        "# is that we do not extract the seasonality component within\n",
        "# the day.\n",
        "\n",
        "edf = (\n",
        "    df\n",
        "    .resample('1D').sum() # we will work with daily data\n",
        "    .reset_index() # make the datetime index a regular column\n",
        "    .filter( items = ['DATE_TIME', 'ERCOT']) # keep only datetime and ERCOT\n",
        "    .rename( # prophet requires specific names for time (\"ds\") and for the time series (\"y\")\n",
        "        {\n",
        "          'DATE_TIME': 'ds',\n",
        "          'ERCOT': 'y'\n",
        "        },\n",
        "        axis=\"columns\" )\n",
        ")\n",
        "\n",
        "\n",
        "# This dataframe is ready for Prophet\n",
        "edf\n"
      ],
      "metadata": {
        "id": "_Rq5Jb04tsNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the daily usage:\n",
        "edf.plot(y='y', x='ds')"
      ],
      "metadata": {
        "id": "orENDUeZEtfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = Prophet(seasonality_mode='multiplicative')\n",
        "\n",
        "# We ask to also add the US holidays as regressors\n",
        "m.add_country_holidays(country_name='US')\n",
        "\n",
        "# Take as input the time series and extract the components\n",
        "m.fit(edf)"
      ],
      "metadata": {
        "id": "VRsUAlNDuPvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup for hourly forecasts, one year in the future\n",
        "# future = m.make_future_dataframe(periods=365 * 24, freq='H')\n",
        "\n",
        "# Setup for daily forecasts, one year in the future\n",
        "future = m.make_future_dataframe(periods=365)\n",
        "future.tail()"
      ],
      "metadata": {
        "id": "TmIRvn5ivZEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast = m.predict(future)\n",
        "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n"
      ],
      "metadata": {
        "id": "sBmk-wP7vh9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig1 = m.plot(forecast)"
      ],
      "metadata": {
        "id": "2JEwsh_fvn0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig2 = m.plot_components(forecast)"
      ],
      "metadata": {
        "id": "tRFGnoTewhpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_plotly(m, forecast)"
      ],
      "metadata": {
        "id": "G7yxf2MI0XLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_components_plotly(m, forecast)"
      ],
      "metadata": {
        "id": "CF8B0mxm0YqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Evaluation\n",
        "\n",
        "Prophet includes functionality for time series cross validation to measure forecast error using historical data. This is done by selecting cutoff points in the history, and for each of them fitting the model using data only up to that cutoff point. We can then compare the forecasted values to the actual values."
      ],
      "metadata": {
        "id": "oKlLvSkq-5H-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training, validation, forecast\n",
        "\n",
        "* **Training**: Data in the *initial* or *estimation* or *training* period are used to help select the model and to estimate its parameters. Forecasts made in this period are not really \"honest\" because data on both sides of each observation are used to help determine the forecast.\n",
        "\n",
        "* **Validation**: Data in the *validation* or *horizon* period are not given to the algorithm while creating the model and are *held out* during model training. Instead, we use the data in this period to evaluate the quality of the forecasting. Often the results of the evaluation are called ***backtests***.\n",
        "\n",
        "* **Forecast**: This is the time period for which we make our actual forecasts. Please note that even if we do have data for the forecasting period, these should not be used to guide the selection of our algorithm or other settings of our algorithm."
      ],
      "metadata": {
        "id": "MhpNWzzgBL4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://facebook.github.io/prophet/static/diagnostics_files/diagnostics_4_0.png\">"
      ],
      "metadata": {
        "id": "lQ009ILFAmUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 1: Cross-validation with moving cutoffs\n",
        "df_cv = cross_validation(m,\n",
        "      initial='730 days', # We will take the first two years of the data\n",
        "      horizon = '365 days', # and we will make predictions for one year\n",
        "      period='180 days', # then we will move the cutoff 180 days forward and continue\n",
        "                         # until we reach the end of the time series\n",
        "                         # (for our series with 21 years of data, minus two\n",
        "                         # years for starting the training, this results\n",
        "                         # in 38 different cutoff dates used for evaluation)\n",
        "      parallel=\"processes\" # speedup using parallelism\n",
        "      )\n"
      ],
      "metadata": {
        "id": "Op2Y-1urAEIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cv # This shows our predictions (y_hat) against the actual value (y)\n",
        "      # and also shows lower and upper estimates for y_hat."
      ],
      "metadata": {
        "id": "bBz4lW7NGa2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 2: We explicitly specify the cutoffs\n",
        "\n",
        "cutoffs = pd.to_datetime(['2019-01-01', '2020-01-01', '2021-01-01'])\n",
        "\n",
        "# Use the three cutoffs above and make predictions for 365 days after the cutoff\n",
        "df_cv2 = cross_validation(m, cutoffs=cutoffs, horizon='365 days')\n",
        "df_cv2"
      ],
      "metadata": {
        "id": "IiZ837iyJNE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation metrics\n",
        "\n",
        "There are many metrics that can be used to evaluate the quality of the forecasts\n",
        "\n",
        "* **MSE (Mean Squared Error)**: Measures the average squared difference between the predicted and actual values in a time series.\n",
        "* **RMSE (Root Mean Squared Error)**: The square root of the MSE, providing a measure of the average magnitude of the prediction errors.\n",
        "* **MAE (Mean Absolute Error)**: Calculates the average absolute difference between the predicted and actual values, ignoring the direction of errors.\n",
        "* **MAPE (Mean Absolute Percentage Error)**: Computes the average percentage difference between the predicted and actual values, relative to the actual values.\n",
        "* **MDAPE (Median Absolute Percentage Error)**: Similar to MAPE, but uses the median instead of the mean, making it more robust to outliers.\n",
        "* **SMAPE (Symmetric Mean Absolute Percentage Error)**: A symmetric variant of MAPE that avoids division by zero and handles overestimations and underestimations equally.\n",
        "* **COVERAGE**: Represents the proportion of observed values that fall within a certain prediction interval or confidence interval, indicating the reliability of the forecasts.\n",
        "\n",
        "\n",
        "The popularity and usage of specific metrics for time series evaluation can vary depending on the context and the specific requirements of the problem at hand. However, some commonly used metrics are:\n",
        "\n",
        "* MSE (Mean Squared Error): It is a widely used metric for measuring the overall accuracy of predictions and is often used in regression tasks.\n",
        "* RMSE (Root Mean Squared Error): RMSE is frequently used as it provides an easily interpretable measure of the average prediction error in the same units as the target variable.\n",
        "* MAE (Mean Absolute Error): MAE is popular due to its simplicity and ease of interpretation, as it gives an average of the absolute differences between predicted and actual values.\n",
        "* MAPE (Mean Absolute Percentage Error): MAPE is commonly used when it is important to understand the percentage error in predictions relative to the actual values.\n",
        "* SMAPE (Symmetric Mean Absolute Percentage Error): SMAPE is utilized when it is necessary to account for both overestimations and underestimations in the predictions."
      ],
      "metadata": {
        "id": "kcnG-uw3Da31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manual calculation of performance metrics"
      ],
      "metadata": {
        "id": "aAIzNhYQO0eD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cv"
      ],
      "metadata": {
        "id": "oh26OuHpNZJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MAPE which is defined a \"MAPE = abs(actual - prediction) / abs(prediction)\"\n",
        "df_cv['mape'] = np.abs(df_cv['y'] - df_cv['yhat']) / np.abs(df_cv['y'])"
      ],
      "metadata": {
        "id": "IdgJrAx2GV_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cv['horizon'] = df_cv['ds'] - df_cv['cutoff']"
      ],
      "metadata": {
        "id": "Uq-Id9tUMEPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cv.pivot_table(\n",
        "    index = 'horizon',\n",
        "    values = 'mape',\n",
        "    aggfunc = 'mean'\n",
        ").plot(\n",
        "    figsize = (12,2)\n",
        ")"
      ],
      "metadata": {
        "id": "oeD_cX3cR481"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let's visualize the MAPE metric as a function of the horizon length\n",
        "# using a violin plot, to understand not only the mean but also the distribution\n",
        "\n",
        "\n",
        "# Create categories/bins for grouping the x-axis values\n",
        "# Grouping into 7 bins\n",
        "bins = [0, 50, 100, 150, 200, 250, 300, 365]\n",
        "labels = ['0-50', '50-100', '100-150', '150-200', '200-250', '250-300', '300-365']\n",
        "# Convert horizon to a number (instead of a \"x days\")\n",
        "df_cv['horizon_length'] = df_cv['horizon'].dt.total_seconds() / (24 * 60 * 60)\n",
        "# and group the numbers into predefined ranges\n",
        "df_cv['horizon_length'] = pd.cut(df_cv['horizon_length'], bins=bins, labels=labels)\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "ax = sns.violinplot(\n",
        "    data = df_cv,\n",
        "    x = 'horizon_length',\n",
        "    y = 'mape',\n",
        ")"
      ],
      "metadata": {
        "id": "kLw9AYaEL_C3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Automatic calculation of performance metrics"
      ],
      "metadata": {
        "id": "NRn0mSWXRw1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's see how we can calculate these metrics using the Prophet package"
      ],
      "metadata": {
        "id": "qj78Tl3MEj7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `performance_metrics` utility can be used to compute some useful statistics of the prediction performance (yhat, yhat_lower, and yhat_upper compared to y), as a function of the distance from the cutoff (how far into the future the prediction was). The statistics computed are mean squared error (MSE), root mean squared error (RMSE), mean absolute error (MAE), mean absolute percent error (MAPE), median absolute percent error (MDAPE) and coverage of the yhat_lower and yhat_upper estimates. These are computed on a rolling window of the predictions in df_cv after sorting by horizon (ds minus cutoff). By default 10% of the predictions will be included in each window, but this can be changed with the rolling_window argument."
      ],
      "metadata": {
        "id": "206lDjqZGWYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_p = performance_metrics(df_cv)"
      ],
      "metadata": {
        "id": "MNiID6pjF9Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p"
      ],
      "metadata": {
        "id": "h_nzUyZiSaTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p.plot(\n",
        "    x = 'horizon',\n",
        "    y = 'mape',\n",
        "    figsize = (16,2)\n",
        ")"
      ],
      "metadata": {
        "id": "RE9i3jbmHvOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A Prophet-provided visualization that shows the average value of the metric\n",
        "# (blue line) against the various measurements in different points in time\n",
        "\n",
        "fig = plot_cross_validation_metric(df_cv, metric='mape')\n",
        "# Get the Axes object from the Figure\n",
        "ax = fig.get_axes()[0]\n",
        "ax.set_ylim(0, 0.2)"
      ],
      "metadata": {
        "id": "zq4V9GELGA6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xcQ4SJdE_GFt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "ERCOT.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}