{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A-Introduction_to_Pandas",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeirotis/dealing_with_data/blob/master/01-Pandas/B1-Pandas_Reading_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fdYUrR2RPLK"
      },
      "source": [
        "# Introduction to Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycUTUOp0RPLL"
      },
      "source": [
        "## Setup and preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the necessary libraries to connect to MySQL and to read Excel files"
      ],
      "metadata": {
        "id": "0p4nxRUUNjqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo pip3 install -U -q PyMySQL sqlalchemy sql_magic xlrd"
      ],
      "metadata": {
        "id": "utQbDZCIrJSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs9khdOxRPLS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou04bj1STXa4"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas offers the ability to read and write from/to many different data types. We list a few examples below, and we have a [small example](https://github.com/ipeirotis/dealing_with_data/blob/master/03-Pandas/E2-Reading_from_Web_Pages.ipynb) where we read directly tables from web pages. The [official documentation](https://pandas.pydata.org/docs/reference/io.html) has the full list."
      ],
      "metadata": {
        "id": "znhDezG1Twq-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRkwgJ2BRPLl"
      },
      "source": [
        "## Loading data from MySQL Server using the `read_sql` command"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DOH Restaurant Inspections"
      ],
      "metadata": {
        "id": "j2D_RqENq1Oy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YF27gS9RPLl"
      },
      "source": [
        "We start by setting up the connection to the MySQL server that we want to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5GO33l5RPLm"
      },
      "source": [
        "import os\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy import text\n",
        "\n",
        "conn_string = 'mysql+pymysql://{user}:{password}@{host}/{db}?charset=utf8mb4'.format(\n",
        "    host = 'db.ipeirotis.org', \n",
        "    user = 'student',\n",
        "    password = 'dwdstudent2015', \n",
        "    db = 'doh_restaurants',\n",
        "    encoding = 'utf8mb4')\n",
        "\n",
        "engine = create_engine(conn_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNsW_56mRPLq"
      },
      "source": [
        "We fetch the results of the query using the `read_sql` command."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This query returns back the restaurants in the DOH database\n",
        "sql = '''\n",
        "\tSELECT R.CAMIS, R.DBA, R.BUILDING, R.STREET, R.ZIPCODE, R.BORO, \n",
        "          R.CUISINE_DESCRIPTION, R.LATITUDE, R.LONGITUDE\n",
        "\t\tFROM doh_restaurants.restaurants R\n",
        "\n",
        "'''\n",
        "\n",
        "with engine.connect() as connection:\n",
        "\trestaurants = pd.read_sql(text(sql), con=connection)\n"
      ],
      "metadata": {
        "id": "xlfDX5AtvG58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13OxAtwORPLt"
      },
      "source": [
        "When you run your query using Pandas, you get back a kind of object called a DataFrame, which is made up of rows and columns. Let's take a look at how the object looks like:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "restaurants"
      ],
      "metadata": {
        "id": "yi6DLJiJvcH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading a CSV file using the `read_csv` command"
      ],
      "metadata": {
        "id": "bhoPbZpnG7KY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2018 Central Park Squirrel Census\n",
        "\n",
        "Let's get the [2018 Central Park Squirrel Census](https://data.cityofnewyork.us/Environment/2018-Central-Park-Squirrel-Census-Squirrel-Data/vfnx-vebw)"
      ],
      "metadata": {
        "id": "-MTQH8qHHvy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 1: Download the CSV dataset using \n",
        "# the \"!curl\" command (a Linux command line)\n",
        "# To get the URL, go to \"Export => CSV\" and then copy the link\n",
        "!curl https://data.cityofnewyork.us/api/views/vfnx-vebw/rows.csv?accessType=DOWNLOAD -o squirrel_census.csv\n",
        "squirrels = pd.read_csv(\"squirrel_census.csv\")"
      ],
      "metadata": {
        "id": "AM0r8I2ZG7d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 2: Read the URL directly\n",
        "# Fine for small datasets, not great when you have a big dataset and \n",
        "# may want to reload it repeatedly\n",
        "url = 'https://data.cityofnewyork.us/api/views/vfnx-vebw/rows.csv?accessType=DOWNLOAD'\n",
        "squirrels = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "nmPLZFnzIrmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squirrels"
      ],
      "metadata": {
        "id": "fmRGqb1Qj8Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data maniputation techniques (optional)\n",
        "\n",
        "Below, we apply a variety of data maniputation techniques to improve the dataset."
      ],
      "metadata": {
        "id": "B7PjdOwVkC_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The command below adds underscores in all column names and capitalizes them\n",
        "cols = squirrels.columns.map(lambda x: x.replace(' ', '_').upper())\n",
        "squirrels.columns = cols"
      ],
      "metadata": {
        "id": "UVNfw7-AIN3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes\n",
        "# for the meaning of the \"format\" variable\n",
        "squirrels['DATE'] = pd.to_datetime(squirrels['DATE'], format='%m%d%Y')"
      ],
      "metadata": {
        "id": "ujaA0BOPgPPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the column \"LAT/LONG\"\n",
        "squirrels = squirrels.drop([\"LAT/LONG\"], axis = \"columns\")"
      ],
      "metadata": {
        "id": "F1fEHJ2xhXBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squirrels"
      ],
      "metadata": {
        "id": "jo9aceEjh2Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading an Excel file using the `read_excel` command"
      ],
      "metadata": {
        "id": "-HxANPsZOJvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Titanic Dataset \n",
        "\n",
        "Let's now load the [Titanic dataset](https://www.openml.org/search?type=data&sort=runs&id=40945&status=active) from an Excel file.\n",
        "\n"
      ],
      "metadata": {
        "id": "9Uq5oQWNOZJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_url = 'https://storage.googleapis.com/datasets_nyu/titanic.xls'\n",
        "titanic = pd.read_excel(titanic_url)\n",
        "titanic"
      ],
      "metadata": {
        "id": "_F9gKjQ6G7l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Dictionary for DOH Restaurants dataset\n",
        "\n",
        "The [DOHMH New York City Restaurant Inspection Results](https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j) contains a pointer to an Excel file called the \"data dictionary\". Let's download it and see how it looks like."
      ],
      "metadata": {
        "id": "W3jGycLniOG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://data.cityofnewyork.us/api/views/43nn-pn8j/files/ec33d2c8-81f5-499a-a238-0213a38239cd?download=true&filename=RestaurantInspectionDataDictionary_09242018.xlsx'"
      ],
      "metadata": {
        "id": "F9guvC38iYbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurants_data_dictionary = pd.read_excel (url, sheet_name=1, header=1);"
      ],
      "metadata": {
        "id": "6toNPQCpiUu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurants_data_dictionary"
      ],
      "metadata": {
        "id": "-QCBtXA_kmFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the columns\n",
        "restaurants_data_dictionary.columns = ['Column_Name', 'Description', 'Code_Definitions', 'Notes']"
      ],
      "metadata": {
        "id": "0nZ2a-hziU2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the first line\n",
        "restaurants_data_dictionary = restaurants_data_dictionary.drop(0, axis='index')"
      ],
      "metadata": {
        "id": "JQMB64YPijo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurants_data_dictionary"
      ],
      "metadata": {
        "id": "8LQChJEUigkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading a \"Fixed Width\" file using the `read_fwf` command"
      ],
      "metadata": {
        "id": "X-3XBSOOPizA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accidental Deaths in the USA \n",
        "\n",
        "This [dataset](https://storage.googleapis.com/datasets_nyu/acc-deaths.txt) is in \"fixed width\" format  and contains the monthly totals of accidental deaths in the USA. "
      ],
      "metadata": {
        "id": "J-VEWdJzPqUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deaths = pd.read_fwf(\"https://storage.googleapis.com/datasets_nyu/acc-deaths.txt\")\n",
        "deaths"
      ],
      "metadata": {
        "id": "V2z13boZPb7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data maniputation techniques (optional)\n",
        "\n",
        "Below, we apply a variety of data maniputation techniques to improve the dataset."
      ],
      "metadata": {
        "id": "W6eEfHWXk8B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Melt and Pivot_Table\n",
        "\n",
        "Now we want to take the month-columns, and convert the file into a file with the format `<date>, <value>`.\n",
        "\n",
        "The command for this is the [`melt`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html) command. (For the opposite operation, use the pivot_table function.)"
      ],
      "metadata": {
        "id": "WgNu8USum6X4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unpivoted_deaths = pd.melt(deaths, id_vars=['Year'], \n",
        "        value_vars=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
        "        var_name='Month', value_name='Deaths')\n",
        "unpivoted_deaths.head(10)"
      ],
      "metadata": {
        "id": "bNfaVZptm3lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The opposite of melt:\n",
        "unpivoted_deaths.pivot_table(\n",
        "    index='Year',\n",
        "    columns='Month',\n",
        "    values = 'Deaths'\n",
        ")"
      ],
      "metadata": {
        "id": "Gom7LXN1p-mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we want to merge the month and year columns, to create a Date column.\n",
        "# Notice the use of .astype(str) function that converts the int64 datatype into a string.\n",
        "# Without that function, we get an error message that we cannot add an integer (Year) with a string (Month)\n",
        "unpivoted_deaths[\"Date\"] = unpivoted_deaths[\"Month\"] + \"-\" + unpivoted_deaths[\"Year\"].astype(str)\n",
        "unpivoted_deaths"
      ],
      "metadata": {
        "id": "7k4MpXpgnMP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the date column to a proper DateTime data type\n",
        "unpivoted_deaths[\"Date\"] = pd.to_datetime(unpivoted_deaths[\"Date\"], format='%b-%Y')\n",
        "unpivoted_deaths"
      ],
      "metadata": {
        "id": "pn3aiK_QnThg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, that we have the Date column, we can delete the month and year columns.\n",
        "# Notice the axis='columns' part: this means that we drop a column with that name. \n",
        "# If we used axis='rows', then Pandas would have been looking for a row with that key to drop.\n",
        "\n",
        "unpivoted_deaths = unpivoted_deaths.drop([\"Month\",\"Year\"], axis='columns')\n"
      ],
      "metadata": {
        "id": "36F3CW_tnZHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And now we convert the Date to be an index, so that it can be used as the x-axis for plotting the series.\n",
        "unpivoted_deaths = unpivoted_deaths.set_index(keys=\"Date\")\n"
      ],
      "metadata": {
        "id": "sPdCzIDzoCXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice that the dates are not in order (we get the January's for all the \n",
        "# years first, then the February's etc). While this is not an issue with \n",
        "# plotting, this can be an issue for other types of analyses. \n",
        "# For this reason, we sort the index:\n",
        "\n",
        "unpivoted_deaths = unpivoted_deaths.sort_index()"
      ],
      "metadata": {
        "id": "tzbFjrsSpi92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unpivoted_deaths.plot()"
      ],
      "metadata": {
        "id": "29__ctQEnyYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZIRsPfkbFRN"
      },
      "source": [
        "## Loading Tables from HTML Pages using the `read_html` command"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve Country Population From Wikipedia"
      ],
      "metadata": {
        "id": "GrWjg5-te0iP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_population_(United_Nations)'\n",
        "\n",
        "# The \"read_html\" returns back a list of \"dataframes\", one for each table in the web page\n",
        "df_list = pd.read_html(\n",
        "            url, # Specify the page \n",
        "            match='Population', # Write a pattern that is unique to the table we are interested in\n",
        "            header=0 # which line of the table to use as a header\n",
        "        )\n",
        "\n",
        "len(df_list) # check how many tables match"
      ],
      "metadata": {
        "id": "315vrWvNey-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We get the first table in the list, which contains the population of the countries\n",
        "df_population = df_list[0]\n",
        "df_population"
      ],
      "metadata": {
        "id": "3jOynaLse3ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the footnote notations in square brackets (eg., \"[4]\")\n",
        "# The code uses regular expressions for removing the unecessary text\n",
        "df_population = df_population.replace(\n",
        "    to_replace = r'(.*)\\[.\\]',\n",
        "    value = r'\\1',\n",
        "    regex=True\n",
        ")"
      ],
      "metadata": {
        "id": "I74JmiLne5TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the columns\n",
        "df_population.columns = ['Country', 'Region', 'Subegion', 'Population_2022', 'Population_2023', 'Change']"
      ],
      "metadata": {
        "id": "r6zApSwEe70t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only the columns we need\n",
        "df_population = df_population.filter( items = ['Country', 'Population_2023'] )"
      ],
      "metadata": {
        "id": "gNVrBAoLgJXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_population"
      ],
      "metadata": {
        "id": "U1Cuznooe76R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Pyh3VxifVMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve Life Expectancy From Wikipedia"
      ],
      "metadata": {
        "id": "SwCDCw0afV9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_life_expectancy'\n",
        "df_list = pd.read_html(\n",
        "            url, # Specify the page \n",
        "            match='Life expectancy at birth', # Write a pattern that is unique to the table we are interested in\n",
        "            header=0 # which line of the table to use as a header\n",
        "        )\n",
        "\n",
        "len(df_list) # check how many tables match\n"
      ],
      "metadata": {
        "id": "If_hyapJfYaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_who=df_list[0] # get the first of the tables\n",
        "df_who\n"
      ],
      "metadata": {
        "id": "vEKNB_30faYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only two columns\n",
        "df_who = df_who.filter( items = ['Countries and regions', 'Life expectancy at birth'] )\n",
        "# Delete the first two lines of the dataset\n",
        "df_who = df_who.drop([0])\n",
        "df_who"
      ],
      "metadata": {
        "id": "MAUneYVpfb4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'Life expectancy at birth' column to numeric\n",
        "# and store it in a column called \"Life_Expectancy\"\n",
        "df_who['Life_expectancy'] = pd.to_numeric(df_who['Life expectancy at birth'])\n",
        "# Delete the original column\n",
        "df_who = df_who.drop('Life expectancy at birth', axis='columns')\n",
        "df_who"
      ],
      "metadata": {
        "id": "B-3d06eRfz5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_who"
      ],
      "metadata": {
        "id": "rKthioxDf1xu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}