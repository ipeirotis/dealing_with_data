{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "NYPD Vehicle Collisions",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeirotis/dealing_with_data/blob/master/01-Pandas/A3-NYPD_Vehicle_Collisions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSFnJi2tcLWg"
      },
      "source": [
        "# Introduction to Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fabZhDl3cLWh"
      },
      "source": [
        "## Setup and preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpsY77lScLWj"
      },
      "source": [
        "!pip3 install -U -q PyMySQL sqlalchemy sql_magic xlrd\n",
        "\n",
        "# Render our plots inline\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Make the graphs a bit bigger\n",
        "matplotlib.style.use(['seaborn-talk', 'seaborn-ticks', 'seaborn-whitegrid'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We install the geospatial libraries to be used for Task 10 (if desired)\n",
        "\n",
        "!apt-get -qq install -y  libgeos-dev libproj-dev proj-data proj-bin libgdal-dev libspatialindex-dev\n",
        "!pip install -q -U shapely rtree pygeos\n",
        "!pip install -q geopandas descartes\n",
        "\n",
        "import geopandas as gpd\n",
        "\n",
        "# Dataset from NYC Open Data: https://data.cityofnewyork.us/City-Government/Neighborhood-Tabulation-Areas/cpf4-rkhq\n",
        "df_nyc = gpd.GeoDataFrame.from_file('https://data.cityofnewyork.us/api/geospatial/cpf4-rkhq?method=export&format=Shapefile')\n"
      ],
      "metadata": {
        "id": "GZM76yVEeonk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI-dq-9ZcLWq"
      },
      "source": [
        "## Exercise: NYPD Vehicle Collisions\n",
        "\n",
        "* We interacted with the NYC Restaurant Inspection Data. Now, let's download another dataset, and do some analysis. We will focus on the [NYPD Vehicle Collisions](https://data.cityofnewyork.us/Public-Safety/NYPD-Motor-Vehicle-Collisions/h9gi-nx95/data) data set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "1leSJW23cLWr"
      },
      "source": [
        "### Task 1\n",
        "\n",
        "Load the dataset for all the collisions after Jan 1st, 2020. We will need to load two tables, with the appropriate date restrictions:\n",
        "\n",
        "* `collisions`\n",
        "* `vehicles_involved`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "kraQtxBicLWs"
      },
      "source": [
        "import os\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy import text\n",
        "\n",
        "conn_string = 'mysql+pymysql://{user}:{password}@{host}/{db}?charset=utf8mb4'.format(\n",
        "    host = 'db.ipeirotis.org',\n",
        "    user = 'student',\n",
        "    password = 'dwdstudent2015',\n",
        "    db = 'collisions',\n",
        "    encoding = 'utf8mb4')\n",
        "\n",
        "engine  = create_engine(conn_string)\n",
        "\n",
        "# mysql_conn.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "KmWXZ8LtcLWw"
      },
      "source": [
        "# This query returns back the collisions table\n",
        "# sql = '''\n",
        "    #YOUR CODE HERE\n",
        "# '''\n",
        "# with engine.connect() as connection:\n",
        "#\tc = pd.read_sql(text(sql), con=connection)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ZQyVC6iXU-4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This query returns back the vehicles_involved table\n",
        "# sql = '''\n",
        "    #YOUR CODE HERE\n",
        "# '''\n",
        "# with engine.connect() as connection:\n",
        "#\tv = pd.read_sql(text(sql), con=connection)"
      ],
      "metadata": {
        "id": "qIV65MT8oyI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "solution2_first": true,
        "id": "iE7pp12icLW0"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "id": "IkjES2_scLW1"
      },
      "source": [
        "# This query returns back the collisions table\n",
        "sql = '''\n",
        "\tSELECT *\n",
        "  FROM collisions\n",
        "  WHERE DATE_TIME > '2020-01-01'\n",
        "'''\n",
        "with engine.connect() as connection:\n",
        "\tc = pd.read_sql(text(sql), con=connection)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "id": "hxe1o7AJcLW7"
      },
      "source": [
        "# This query returns back the vehicles_involved table\n",
        "sql = '''\n",
        "\tSELECT *\n",
        "  FROM vehicles_involved\n",
        "  WHERE UNIQUE_KEY IN (\n",
        "  \tSELECT UNIQUE_KEY\n",
        "    FROM collisions\n",
        "    WHERE DATE_TIME > '2020-01-01'\n",
        "  )\n",
        "'''\n",
        "with engine.connect() as connection:\n",
        "\tv = pd.read_sql(text(sql), con=connection)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c.memory_usage(deep=True)"
      ],
      "metadata": {
        "id": "SHSfiVWSYvWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory optimization, should not have any effect except for speed\n",
        "\n",
        "# We do not need the highest level of precision\n",
        "c['LATITUDE'] = pd.to_numeric(c['LATITUDE'], downcast='float')\n",
        "c['LONGITUDE'] = pd.to_numeric(c['LONGITUDE'], downcast='float')\n",
        "\n",
        "# Convert from strings to categorical variables, saves significant amount\n",
        "# of data for columns with just a few values\n",
        "c['BOROUGH'] = pd.Categorical(c['BOROUGH'])\n",
        "c['NEIGHBORHOOD'] = pd.Categorical(c['NEIGHBORHOOD'])\n",
        "c['ZIPCODE'] = pd.Categorical(c['ZIPCODE'])\n",
        "\n",
        "# Convert from high precision double to unsigned int (1 byte per entry)\n",
        "c['PERSONS_INJURED'] = pd.to_numeric(c['PERSONS_INJURED'], downcast='unsigned')\n",
        "c['PERSONS_KILLED'] = pd.to_numeric(c['PERSONS_KILLED'], downcast='unsigned')\n",
        "c['PEDESTRIANS_INJURED'] = pd.to_numeric(c['PEDESTRIANS_INJURED'], downcast='unsigned')\n",
        "c['PEDESTRIANS_KILLED'] = pd.to_numeric(c['PEDESTRIANS_KILLED'], downcast='unsigned')\n",
        "c['CYCLISTS_INJURED'] = pd.to_numeric(c['CYCLISTS_INJURED'], downcast='unsigned')\n",
        "c['CYCLISTS_KILLED'] = pd.to_numeric(c['CYCLISTS_KILLED'], downcast='unsigned')\n",
        "c['MOTORISTS_INJURED'] = pd.to_numeric(c['MOTORISTS_INJURED'], downcast='unsigned')\n",
        "c['MOTORISTS_KILLED'] = pd.to_numeric(c['MOTORISTS_KILLED'], downcast='unsigned')\n",
        "\n",
        "# Remove columns that we do not need\n",
        "c = c.drop(\n",
        "    ['ON_STREET_NAME', 'CROSS_STREET_NAME', 'OFF_STREET_NAME', 'REPORTED_ZIPCODE', 'REPORTED_BOROUGH'],\n",
        "    axis = 'columns'\n",
        ")"
      ],
      "metadata": {
        "id": "cyKGkgeVYNE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c.memory_usage(deep=True)"
      ],
      "metadata": {
        "id": "zqhDV4LIZNvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory optimization, should not have any effect except for speed\n",
        "\n",
        "# Convert from strings to categorical variables, saves significant amount\n",
        "# of data for columns with just a few values\n",
        "v['VEHICLE'] = pd.Categorical(v['VEHICLE'])\n",
        "v['CAUSE'] = pd.Categorical(v['CAUSE'])\n",
        "v['VEHICLE_TYPE'] = pd.Categorical(v['VEHICLE_TYPE'])\n"
      ],
      "metadata": {
        "id": "yTDMHzHobtBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "id": "b0qlf_0UcLW_"
      },
      "source": [
        "c.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v.dtypes"
      ],
      "metadata": {
        "id": "2dJNa4bLoLct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "vy3dI2TIcLXF"
      },
      "source": [
        "### Task 2\n",
        "\n",
        "Find out the most common contributing factors to the collisions, for all accidents after Jan-1-2020. You can either use the dataframe that we loaded above (`vehicles_involved`)  or issue an SQL query and fetch a new dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "GzobFdbrcLXG"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "solution2_first": true,
        "id": "2QrwsfQscLXO"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "id": "tIlEGYKvcLXP"
      },
      "source": [
        "# Task 2: Find out the most common contributing factors to the collisions.\n",
        "v['CAUSE'].value_counts() #.plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RDW8dHufVnl"
      },
      "source": [
        "# Task 2: If we want to remove the \"Unspecified\", we select the elements starting\n",
        "# from position 1 (i.e., the second element in the list, the first one is 0)\n",
        "v['CAUSE'].value_counts()[1:10].plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the  difference if we use \"COUNT(DISTINCT UNIQUE_KEY)\"\n",
        "# instead of COUNT(*). The former counts accidents, the later vehicles\n",
        "factors_sql = '''\n",
        "\tSELECT CAUSE, COUNT(*) AS cnt\n",
        "  FROM vehicles_involved\n",
        "  WHERE UNIQUE_KEY IN (\n",
        "  \tSELECT UNIQUE_KEY\n",
        "    FROM collisions\n",
        "    WHERE DATE_TIME > '2020-01-01'\n",
        "  )\n",
        "  GROUP BY CAUSE\n",
        "  ORDER BY cnt DESC\n",
        "'''\n",
        "\n",
        "with engine.connect() as connection:\n",
        "\tfactors_df = pd.read_sql(text(factors_sql), con=connection)\n",
        "\n",
        "factors_df.head(10)"
      ],
      "metadata": {
        "id": "ra2gLC5Li65b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        " factors_df\n",
        " .set_index('CAUSE') # Make \"CAUSE\" the x-axis for the plot\n",
        " .head(10) # keep the top-10 factors\n",
        " #.tail(9) # uncomment if you want to eliminate \"UNSPECIFIED\" (the top-1)\n",
        " .sort_values('cnt')\n",
        " .plot(\n",
        "     kind='barh',\n",
        "     figsize=(10,4)\n",
        "  )\n",
        ")"
      ],
      "metadata": {
        "id": "frAn_Ep6jgsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "oYf_YojlcLXT"
      },
      "source": [
        "### Task 3\n",
        "\n",
        "Break down the number of collisions by borough.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "U6q_kRFHcLXT"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "solution2_first": true,
        "id": "tD2DFonOcLXg"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "id": "xTVPuKmvcLXi"
      },
      "source": [
        "# Task 3: Break down the number of collisions by borough.\n",
        "c['BOROUGH'].value_counts().plot(kind='barh', figsize=(10,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice that you can remove the date time restriction and you\n",
        "# will get the results back equally fast. If you try to load the\n",
        "# whole collisions table in a dataframe, and then do the value_counts\n",
        "# or a pivot table, it may take quite a while.\n",
        "\n",
        "boro_sql = '''\n",
        "\tSELECT BOROUGH, COUNT(*) AS cnt\n",
        "  FROM collisions\n",
        "  WHERE DATE_TIME > '2020-01-01'\n",
        "  GROUP BY BOROUGH\n",
        "  ORDER BY cnt DESC\n",
        "'''\n",
        "\n",
        "with engine.connect() as connection:\n",
        "\tboro_df = pd.read_sql(text(boro_sql), con=connection)\n",
        "\n",
        "(\n",
        "    boro_df\n",
        "    .set_index('BOROUGH')\n",
        "    .plot(kind='barh', figsize=(10,5))\n",
        ")\n"
      ],
      "metadata": {
        "id": "rax0YjB9lWb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "DNn2pls3cLXl"
      },
      "source": [
        "### Task 4\n",
        "\n",
        "Find out the how many collisions had 0 persons injured, 1 persons injured, etc. persons injured in each accident. Use the `value_counts()` approach. You may also find the `.plot(logy=True)` option useful when you create the plot to make the y-axis logarigthmic.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "uzIX6UPDcLXm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "solution2_first": true,
        "id": "76coQlh6cLXs"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "id": "pbu-F_V0cLXt"
      },
      "source": [
        "# \"Chain\" style of writing data maniputation operations\n",
        "plot = (\n",
        "    c['PERSONS_INJURED'] # take the num of injuries column\n",
        "    .value_counts() # compure the freuquency of each value\n",
        "    .sort_index() # sort the results based on the index value instead of the frequency,\n",
        "                  # which is the default for value_counts\n",
        "    .plot( # and plot the results\n",
        "        kind='line', # we use a line plot because the x-axis is numeric/continuous\n",
        "        marker='o',  # we use a marker to mark where we have data points\n",
        "        logy=True # make the y-axis logarithmic\n",
        "    )\n",
        ")\n",
        "plot.set_xlabel(\"Number of injuries\")\n",
        "plot.set_ylabel(\"Number of collisions\")\n",
        "plot.set_title(\"Analysis of number of injuries per collision\")\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "injuries_sql = '''\n",
        "\tSELECT PERSONS_INJURED, COUNT(*) AS cnt\n",
        "  FROM collisions\n",
        "  -- WHERE DATE_TIME > '2020-01-01'\n",
        "  GROUP BY PERSONS_INJURED\n",
        "  ORDER BY cnt DESC\n",
        "'''\n",
        "\n",
        "with engine.connect() as connection:\n",
        "\tinjuries_df = pd.read_sql(text(injuries_sql), con=connection)\n",
        "\n",
        "# \"Chain\" style of writing data maniputation operations\n",
        "plot = (\n",
        "    injuries_df # take the num of injuries column\n",
        "    .set_index('PERSONS_INJURED') # compure the frequency of each value\n",
        "    .sort_index() # sort the results based on the index value instead of the frequency,\n",
        "                  # which is the default for value_counts\n",
        "    .plot( # and plot the results\n",
        "        kind='line', # we use a line plot because the x-axis is numeric/continuous\n",
        "        marker='o',  # we use a marker to mark where we have data points\n",
        "        logy=True # make the y-axis logarithmic\n",
        "    )\n",
        ")\n",
        "plot.set_xlabel(\"Number of injuries\")\n",
        "plot.set_ylabel(\"Number of collisions\")\n",
        "plot.set_title(\"Analysis of number of injuries per collision\")\n",
        "pass"
      ],
      "metadata": {
        "id": "x7-2tzRfo_W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "LEvpWDsDcLXw"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "xXdFK7ivcLXz"
      },
      "source": [
        "### Task 5\n",
        "\n",
        "(a) Compute the average number of injuries and deaths per accident, broken down by borough. Use the `pivot_table` functionality, putting `BOROUGH` as the index. You can answer this query by generating two separate tables, or you can create a single table by using the fact that you can pass a list of attributes/columns to the `values` parameter of the pivot table.\n",
        "\n",
        "(b) Repeat the exercise above, but break down the average number of deaths and injuries using the cause for the accident. (Do not worry that each accident may have multiple causes.) You will need to **join** the tables `collisions` and `vehicles_involves`; you can do the join either in SQL or in pandas, using the `pd.merge` command. Use the `sort_values` command to sort the results, putting on top the contributing factors that generate the highest number of deaths. Limit to the 10-deadliest causes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "AAcrRiMbcLX0"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "solution2_first": true,
        "id": "DjY0HNIkcLX3"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "id": "mSr0uLiucLX4"
      },
      "source": [
        "pd.pivot_table(\n",
        "    data = c,\n",
        "    index = 'BOROUGH',\n",
        "    aggfunc = 'mean',\n",
        "    values = ['PERSONS_INJURED', 'PERSONS_KILLED']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# By keeping only the minimum attributes that we need, we speed up\n",
        "# the execution, as we do not bring back data that we will discard anyway\n",
        "sql = '''\n",
        "  SELECT C.BOROUGH\n",
        "        , AVG(C.PERSONS_INJURED) AS PERSONS_INJURED\n",
        "        , AVG(C.PERSONS_KILLED) AS PERSONS_KILLED\n",
        "  FROM collisions C\n",
        "  WHERE DATE_TIME > '2020-01-01'\n",
        "  GROUP BY C.BOROUGH\n",
        "'''\n",
        "with engine.connect() as connection:\n",
        "\tresult = pd.read_sql(text(sql), con=connection)\n",
        "result.set_index('BOROUGH')"
      ],
      "metadata": {
        "id": "qYZrKA5-rOfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "LXDZ1M3bcLX-"
      },
      "source": [
        "# By keeping only the minimum attributes that we need, we speed up\n",
        "# the execution, as we do not bring back data that we will discard anyway\n",
        "sql = '''\n",
        "  SELECT V.CAUSE\n",
        "        , AVG(C.PERSONS_INJURED) AS PERSONS_INJURED\n",
        "        , AVG(C.PERSONS_KILLED) AS PERSONS_KILLED\n",
        "  FROM collisions C JOIN vehicles_involved V ON C.UNIQUE_KEY = V.UNIQUE_KEY\n",
        "  WHERE DATE_TIME > '2020-01-01'\n",
        "  GROUP BY V.CAUSE\n",
        "'''\n",
        "with engine.connect() as connection:\n",
        "\tresult = pd.read_sql(text(sql), con=connection)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "  result\n",
        " .set_index('CAUSE')\n",
        " .sort_values('PERSONS_KILLED',ascending=False)\n",
        " .head(20)\n",
        "\n",
        ")\n",
        "#"
      ],
      "metadata": {
        "id": "LppeZwoXqn1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "J-xdkmYNcLYA"
      },
      "source": [
        "### Task 6\n",
        "\n",
        "Break down the number of accidents by borough and cause. Use the `pivot_table` function of Pandas, making the values of \"borough\" to be  columns and cause to be rows.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "suQVfLfLcLYB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "solution2_first": true,
        "id": "tzANbIOOcLYE"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# By keeping only the minimum attributes that we need, we speed up\n",
        "# the execution, as we do not bring back data that we will discard anyway\n",
        "sql = '''\n",
        "  SELECT C.BOROUGH,  V.CAUSE, COUNT(DISTINCT C.UNIQUE_KEY) AS cnt\n",
        "  FROM collisions C JOIN vehicles_involved V ON C.UNIQUE_KEY = V.UNIQUE_KEY\n",
        "  WHERE DATE_TIME > '2020-01-01'\n",
        "  GROUP BY C.BOROUGH,  V.CAUSE\n",
        "'''\n",
        "with engine.connect() as connection:\n",
        "\tresult = pd.read_sql(text(sql), con=connection)"
      ],
      "metadata": {
        "id": "4JodzmPMsN03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "id": "qsTyRepUcLYE"
      },
      "source": [
        "pivot = pd.pivot_table(\n",
        "    data = result, # we analyze the df (accidents) dataframe\n",
        "    index = 'CAUSE',\n",
        "    columns = 'BOROUGH',\n",
        "    values = 'cnt',\n",
        "    aggfunc = 'sum'\n",
        ")\n",
        "\n",
        "# Create an extra column showing the total deaths across boroughs (=columns)\n",
        "pivot[\"Total\"] = pivot.sum(axis=\"columns\")\n",
        "\n",
        "# Sort the dataframe by descending order of the values in the column \"Total\"\n",
        "pivot = pivot.sort_values(\"Total\", ascending=False)\n",
        "\n",
        "pivot.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "ySQ9Hif6cLYH"
      },
      "source": [
        "### Task 7\n",
        "\n",
        "Find the dates with the most accidents. Can you figure out what happened on these days?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "lMmhElPNcLYH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "solution2_first": true,
        "id": "lZiZd0UbcLYL"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "  SELECT DATE(DATE_TIME) AS accident_date, COUNT(*) AS cnt\n",
        "  FROM collisions\n",
        "  GROUP BY DATE(DATE_TIME)\n",
        "  ORDER BY cnt DESC\n",
        "'''\n",
        "\n",
        "with engine.connect() as connection:\n",
        "\tdate_df = pd.read_sql(text(sql), con=connection)"
      ],
      "metadata": {
        "id": "LurVvpahwx1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_df"
      ],
      "metadata": {
        "id": "dmCQ1TM6xDFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "id": "RKj3P_oocLYL"
      },
      "source": [
        "(\n",
        "  pd.pivot_table(\n",
        "      data = date_df,\n",
        "      index = 'accident_date',\n",
        "      values = 'cnt',\n",
        "  )\n",
        "  # .resample('1D').sum()\n",
        "  .sort_values('cnt', ascending=False)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "7o9cKVzfcLYP"
      },
      "source": [
        "### Task 8\n",
        "\n",
        "Plot the number of accidents per day. Try to eliminate the effects of seasonality by resampling and calculating values on a weekly or monthly basis (Hint: Ensure that your date column is in the right datatype and that it is properly sorted, before attempting a `resample`)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lcK6ZU1s3Lu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "solution2_first": true,
        "id": "hkLfpTMWcLYW"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "solution2": "hidden",
        "id": "bfVkkcRJcLYZ"
      },
      "source": [
        "(\n",
        "  pd.pivot_table(\n",
        "      data = date_df,\n",
        "      index = 'accident_date',\n",
        "      values = 'cnt',\n",
        "  )\n",
        "  # .resample('1W') # take periods of 1 week\n",
        "  # .sum() # sum the number of accidents per period\n",
        "  .plot(figsize=(15,3)) # plot the result\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdPG02oAYIlB"
      },
      "source": [
        "# Convert the 'accident_date' from 'object' to datetime\n",
        "date_df['date'] = pd.to_datetime(date_df['accident_date'])\n",
        "\n",
        "(\n",
        "  pd.pivot_table(\n",
        "      data = date_df,\n",
        "      index = 'date',\n",
        "      values = 'cnt',\n",
        "  )\n",
        "  .resample('1W') # take periods of 1 week\n",
        "  .sum() # sum the number of accidents per period\n",
        "  .plot(figsize=(15,3)) # plot the result\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKrCSb8D_F13"
      },
      "source": [
        "### Task 9\n",
        "\n",
        "We want to analyze the timing patterns of accidents that lead to death or injury.\n",
        "\n",
        "We will do the analysis by creating histograms showing the frequency of deadly vs non-deadly accidents throughout the day. By comparing the two histograms we will be able to understand if time of day is correlated with deadly accidents or not.\n",
        "\n",
        "Steps to follow:\n",
        "* Create an `HOUR` column that captures the hour of the day that the accident happened.\n",
        "* Create a boolean column `DEATH` that is true when someone was killed in the accident (i.e., `NUMBER OF PERSONS KILLED > 0`).\n",
        "* Create a boolean column `INJURY` that is true when someone was injured in the accident (i.e., `NUMBER OF PERSONS INJURED > 0`).\n",
        "* Query the dataframe to get back the deadly accidents and create a histogram of deadly accidents over time. Do the same for non-deadly accidents.\n",
        "* To allow a more direct visual comparison of the two histograms, we want to merge them in one plot. Since the number of accidents without deaths is *much* higher, we want the histograms to be normalized (i.e., `density=True`).\n",
        "* It is also a good idea to make the histographs partially transparent, to allow for easier comparison of the two histograms.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QTZnjQRWA8PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRtYdNVZXXWj"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5bev6D6X5p4"
      },
      "source": [
        "sql = '''\n",
        "  SELECT UNIQUE_KEY, DATE_TIME\n",
        "        , HOUR(DATE_TIME) AS HOUR\n",
        "        , PERSONS_INJURED>0 AS INJURY\n",
        "        , PERSONS_KILLED>0 AS DEATH\n",
        "  FROM collisions\n",
        "'''\n",
        "\n",
        "with engine.connect() as connection:\n",
        "\tdf = pd.read_sql(text(sql), con=connection)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the two subsets\n",
        "deadly = df.query(\" DEATH == True \")\n",
        "noharm = df.query(\" DEATH == False \")"
      ],
      "metadata": {
        "id": "xoSCRBcP53Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deadly['HOUR'].hist(bins=24)"
      ],
      "metadata": {
        "id": "jIoU0QyhX_Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noharm['HOUR'].hist(bins=24)"
      ],
      "metadata": {
        "id": "DbLV4WDAX_US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deadly['HOUR'].hist(\n",
        "    bins=24, # one bar per hour\n",
        "    figsize=(15,5),  # make the figure bigger\n",
        "    density=True, # normalize the counts\n",
        "    alpha=0.5,  # make the histogram semi-transparent\n",
        "    color='red' # color red the deadly accidents\n",
        ")\n",
        "\n",
        "noharm['HOUR'].hist(\n",
        "    bins=24,\n",
        "    figsize=(15,5),\n",
        "    density=True,\n",
        "    alpha=0.5,\n",
        "    color='green'\n",
        ")"
      ],
      "metadata": {
        "id": "SXuXvEO5WM4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatively:\n",
        "\n",
        "pd.pivot_table(\n",
        "    data = df,\n",
        "    index = 'HOUR',\n",
        "    values = 'DEATH',\n",
        "    aggfunc = 'mean',\n",
        ").plot()"
      ],
      "metadata": {
        "id": "W0T2hMZsYJwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbsUX2GnYhvL"
      },
      "source": [
        "injuries = df.query(\" INJURY == True \")\n",
        "no_injuries = df.query(\" INJURY == False \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrUSHHAdAJ3W"
      },
      "source": [
        "injuries['HOUR'].hist(bins=24,figsize=(15,5), density=True,alpha=0.5, color='red')\n",
        "no_injuries['HOUR'].hist(bins=24,figsize=(15,5), density=True,alpha=0.5, color='green')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatively:\n",
        "\n",
        "pd.pivot_table(\n",
        "    data = df,\n",
        "    index = 'HOUR',\n",
        "    values = 'INJURY',\n",
        "    aggfunc = 'mean',\n",
        ").plot()"
      ],
      "metadata": {
        "id": "pQ9asYImbevK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### And let's do the same analysis over time"
      ],
      "metadata": {
        "id": "D4KQg3rbbiZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "injuries['DATE_TIME'].hist(bins=48,figsize=(20,10), density=True,alpha=0.5, color='red')\n",
        "no_injuries['DATE_TIME'].hist(bins=48,figsize=(20,10), density=True,alpha=0.5, color='green')"
      ],
      "metadata": {
        "id": "xeaP5qB3brqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.pivot_table(\n",
        "    data = df,\n",
        "    index = 'DATE_TIME',\n",
        "    values = 'INJURY',\n",
        "    aggfunc = 'mean',\n",
        ").resample('1W').mean().plot()"
      ],
      "metadata": {
        "id": "9oiUQqxdcE0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCnC6e_SW_SN"
      },
      "source": [
        "deadly['DATE_TIME'].hist(bins=48,figsize=(20,10), density=True,alpha=0.5, color='red')\n",
        "noharm['DATE_TIME'].hist(bins=48,figsize=(20,10), density=True,alpha=0.5, color='green')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.pivot_table(\n",
        "    data = df,\n",
        "    index = 'DATE_TIME',\n",
        "    values = 'DEATH',\n",
        "    aggfunc = 'mean',\n",
        ").resample('1M').mean().plot()"
      ],
      "metadata": {
        "id": "Z2j41yircRW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UO7uDtkAa6B"
      },
      "source": [
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikKjA-TEY0qX"
      },
      "source": [
        "sns.kdeplot(data = df, x ='HOUR', hue='DEATH', common_norm=False, bw_adjust=2, cut=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mjUhIPyWyLC"
      },
      "source": [
        "sns.kdeplot(data = df, x ='HOUR', hue='INJURY', common_norm=False, bw_adjust=2, cut=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 10\n",
        "\n",
        "Create a plot that shows the locations of the cyclist deaths. Filter first for accidents where there was a cyclist fatality, and then use a scatterplot on longitude and latitude. In the next step, create a 2-d kernel density plot to show the same information."
      ],
      "metadata": {
        "id": "BHZy6Mg7G7yF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2GV70Cl4blMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Solution"
      ],
      "metadata": {
        "id": "-54BADRQblwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sql = \"SELECT LONGITUDE, LATITUDE FROM collisions WHERE CYCLISTS_KILLED > 0\"\n",
        "\n",
        "with engine.connect() as connection:\n",
        "\tcyclist_dead = pd.read_sql(text(sql), con=connection)"
      ],
      "metadata": {
        "id": "xS4VIR237nP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    cyclist_dead\n",
        "    .plot(\n",
        "        kind='scatter',\n",
        "        x='LONGITUDE',\n",
        "        y='LATITUDE',\n",
        "        # s=1,\n",
        "        figsize=(10,10)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "1krHl0x8H7GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mzltC-umJWhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scatter = (\n",
        "    cyclist_dead\n",
        "    .plot(\n",
        "        kind='scatter',\n",
        "        x='LONGITUDE',\n",
        "        y='LATITUDE',\n",
        "        figsize=(10,10)\n",
        "    )\n",
        ")\n",
        "\n",
        "sns.kdeplot(\n",
        "    data = cyclist_dead,\n",
        "    x='LONGITUDE',\n",
        "    y='LATITUDE',\n",
        "    shade=True,\n",
        "    gridsize=100,\n",
        "    cmap='rainbow',\n",
        "    alpha=0.75,\n",
        "    n_levels=50,\n",
        "    ax=scatter\n",
        ")"
      ],
      "metadata": {
        "id": "hGSAjb8nJeIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base = df_nyc.plot(\n",
        "    linewidth=0.5,\n",
        "    color='White',\n",
        "    edgecolor='Black',\n",
        "    figsize=(10, 10),\n",
        "    alpha=0.75\n",
        ")\n",
        "\n",
        "scatter = (\n",
        "    cyclist_dead\n",
        "    .plot(\n",
        "        kind='scatter',\n",
        "        x='LONGITUDE',\n",
        "        y='LATITUDE',\n",
        "        ax = base # plot it on top of the NYC boundaries\n",
        "    )\n",
        ")\n",
        "\n",
        "sns.kdeplot(\n",
        "    data = cyclist_dead,\n",
        "    x='LONGITUDE',\n",
        "    y='LATITUDE',\n",
        "    shade=True, # Whether to color between the levels (True) or just keep the contours\n",
        "    gridsize=100, # The resoltion of the 2d plot\n",
        "    cmap='rainbow', # Color scheme\n",
        "    alpha=0.5, # make the 2d density plot a bit transparent\n",
        "    n_levels=20, # calculate 20 levels for the 2d density plot\n",
        "    ax=scatter # plot it on top of the scatter plot\n",
        ")"
      ],
      "metadata": {
        "id": "qcYnGrDn7wgF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
