{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeirotis/dealing_with_data/blob/master/01-Pandas/B2-Storing_from_Pandas_to_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY3jQ0zMkInh"
      },
      "source": [
        "# A Minimal Example of Loading a Dataset to a Database"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U -q PyMySQL sqlalchemy"
      ],
      "metadata": {
        "id": "wnFsH02TktVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv-hqc0kkInq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFprbS3RkInv"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeIJwsNkInx"
      },
      "source": [
        "## Downloading Data and Putting in a Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl 'https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv?accessType=DOWNLOAD' -o restaurants.csv"
      ],
      "metadata": {
        "id": "M1zK8hb7kbvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yr611YQJkInz"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file\n",
        "df = pd.read_csv('restaurants.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding underscores in all column names\n",
        "cols = df.columns\n",
        "cols = cols.map(lambda x: x.replace(' ', '_').upper())\n",
        "df.columns = cols"
      ],
      "metadata": {
        "id": "D3BEnpDwmpvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols"
      ],
      "metadata": {
        "id": "70nAdQbvK9b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5wGqcEUkIn0"
      },
      "outputs": [],
      "source": [
        "# Some bookkeeping regarding datatypes\n",
        "df[\"INSPECTION_DATE\"] = pd.to_datetime(df[\"INSPECTION_DATE\"], format=\"%m/%d/%Y\")\n",
        "df[\"SCORE\"] = pd.to_numeric(df[\"SCORE\"])\n",
        "\n",
        "# Delete useless columns\n",
        "df = df.drop(['GRADE_DATE', 'RECORD_DATE', 'LOCATION_POINT1'], axis='columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create MySQL Connection"
      ],
      "metadata": {
        "id": "9QqKfQZ2ky4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "# Connect to the MySQL, and use the \"public\" database\n",
        "conn_string = 'mysql+pymysql://{user}:{password}@{host}:{port}/{db}?charset=utf8'.format(\n",
        "    user     = 'student',\n",
        "    password = 'dwdstudent2015',\n",
        "    host     = 'db.ipeirotis.org',\n",
        "    port     = 3306,\n",
        "    encoding = 'utf-8',\n",
        "    db = 'public'\n",
        ")\n",
        "engine = create_engine(conn_string)"
      ],
      "metadata": {
        "id": "EbklRLuakklS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the table for storing the data\n",
        "\n",
        "Although we can let Pandas create the table automatically, the choice of data types of not always great. It is better to manually define the data types for the database."
      ],
      "metadata": {
        "id": "1V74LuxWqz-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Report the maximum string lengths for\n",
        "# the textual attributes. Useful when creating\n",
        "# a table in SQL.\n",
        "for c in df.columns.values:\n",
        "  if df.dtypes[c] == 'object':\n",
        "    print(c, df[c].str.len().max())\n"
      ],
      "metadata": {
        "id": "Qf0Tld8TrGVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To avoid conflicts between people writing in the same database, we add a random suffix in the tables\n",
        "# We only create the variable once while running the notebook\n",
        "import uuid\n",
        "if \"suffix\" not in globals():\n",
        "    suffix = str(uuid.uuid4())[:8]\n",
        "print(suffix)"
      ],
      "metadata": {
        "id": "DWSlYTpc7agA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MySQL database that we will use to store the table\n",
        "db_name = \"public\"\n",
        "\n",
        "# The name f the table that we will use\n",
        "table_name = f\"inspections_{suffix}\""
      ],
      "metadata": {
        "id": "yQ76Iioe7nQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFDaggHLkIn2"
      },
      "outputs": [],
      "source": [
        "drop_table_sql = f'''\n",
        "DROP TABLE IF EXISTS {db_name}.{table_name};\n",
        "'''\n",
        "\n",
        "with engine.connect() as con:\n",
        "    con.execute(text(drop_table_sql))\n",
        "\n",
        "\n",
        "create_table_sql = f'''\n",
        "CREATE TABLE IF NOT EXISTS {db_name}.{table_name} (\n",
        "    CAMIS CHAR(8),\n",
        "    DBA VARCHAR(100),\n",
        "    BUILDING VARCHAR(10),\n",
        "    STREET VARCHAR(40),\n",
        "    ZIPCODE CHAR(5),\n",
        "    BORO VARCHAR(15),\n",
        "    PHONE CHAR(12),\n",
        "    CUISINE_DESCRIPTION VARCHAR(30),\n",
        "    LATITUDE FLOAT,\n",
        "    LONGITUDE FLOAT,\n",
        "    COMMUNITY_BOARD CHAR(3),\n",
        "    COUNCIL_DISTRICT CHAR(2),\n",
        "    CENSUS_TRACT CHAR(6),\n",
        "    BIN CHAR(7),\n",
        "    BBL CHAR(10),\n",
        "    NTA CHAR(4),\n",
        "    INSPECTION_DATE DATETIME,\n",
        "    ACTION VARCHAR(130),\n",
        "    GRADE CHAR(1),\n",
        "    INSPECTION_TYPE VARCHAR(60),\n",
        "    VIOLATION_CODE VARCHAR(10),\n",
        "    VIOLATION_DESCRIPTION VARCHAR(1000),\n",
        "    CRITICAL_FLAG VARCHAR(15),\n",
        "    SCORE SMALLINT\n",
        ")  ENGINE=INNODB DEFAULT CHARSET=UTF8MB4;\n",
        "'''\n",
        "\n",
        "with engine.connect() as con:\n",
        "    con.execute(text(create_table_sql))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insert data to DB using the `to_sql` command"
      ],
      "metadata": {
        "id": "K3TNb60isD1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the dataframe as a SQL table, using the to_sql command\n",
        "df.to_sql(name=table_name, # name of the table\n",
        "                   con=engine, # use the connection to MySQL created earlier\n",
        "                   if_exists='append', # we created the empty table above\n",
        "                   index=False, # do not write the index column in the database\n",
        "                   chunksize=1000 # write 1000 lines at a time\n",
        ")"
      ],
      "metadata": {
        "id": "wUsiP9Gto9qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1tX_xYUkIn8"
      },
      "outputs": [],
      "source": [
        "# And then we can just retrieve it from the database\n",
        "with engine.connect() as connection:\n",
        "  r = pd.read_sql(text(f\"SELECT * FROM public.{table_name} LIMIT 100\"), con=connection)\n",
        "r.head(100)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "B2-Pandas_and_SQL-Inserting_Data.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}