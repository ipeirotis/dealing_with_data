{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3: Advanced Data Manipulation Techniques; beyond SQL",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeirotis/dealing_with_data/blob/master/01-Pandas/A3-Advanced_Data_Manipulation_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fdYUrR2RPLK"
      },
      "source": [
        "# Pandas beyond SQL: Advanced Data Manipulation Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the necessary libraries to connect to MySQL and to read Excel files"
      ],
      "metadata": {
        "id": "0p4nxRUUNjqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Setup and preliminaries\n",
        "\n",
        "!pip3 install -U -q PyMySQL sqlalchemy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Render our plots with high resolution\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "# Make the graphs a bit bigger\n",
        "matplotlib.style.use([\"seaborn-v0_8-talk\", \"seaborn-v0_8-ticks\", \"seaborn-v0_8-whitegrid\"])\n",
        "\n",
        "# Setting the default figure size for Pandas plots\n",
        "pd.options.plotting.backend = 'matplotlib'\n",
        "plt.rcParams['figure.figsize'] = [10, 3]"
      ],
      "metadata": {
        "id": "utQbDZCIrJSQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title MySQL Setup\n",
        "\n",
        "import os\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy import text\n",
        "\n",
        "conn_string = 'mysql+pymysql://{user}:{password}@{host}/{db}?charset=utf8mb4'.format(\n",
        "    host = 'db.ipeirotis.org',\n",
        "    user = 'student',\n",
        "    password = 'dwdstudent2025',\n",
        "    db = 'doh_restaurants',\n",
        "    encoding = 'utf8mb4')\n",
        "\n",
        "engine = create_engine(conn_string)\n",
        "\n",
        "# This query returns back the restaurants in the DOH database\n",
        "sql = '''\n",
        "\tSELECT R.CAMIS, R.DBA, R.BUILDING, R.STREET, R.ZIPCODE, R.BORO,\n",
        "          R.CUISINE_DESCRIPTION, R.LATITUDE, R.LONGITUDE, R.NTA\n",
        "\t\tFROM doh_restaurants.restaurants R\n",
        "'''\n",
        "\n",
        "with engine.connect() as connection:\n",
        "\trestaurants = pd.read_sql(text(sql), con=connection)\n",
        "\n",
        "# This query returns back the results of the inspections of each restaurant\n",
        "sql = '''\n",
        "\tSELECT R.CAMIS, R.DBA, R.ZIPCODE, R.BORO, R.CUISINE_DESCRIPTION, R.NTA,\n",
        "\t\t\t\t I.INSPECTION_DATE, I.INSPECTION_ID,\n",
        "\t\t\t\t I.INSPECTION_TYPE, I.SCORE, I.GRADE\n",
        "\tFROM restaurants R\n",
        "\t\tJOIN inspections I ON I.CAMIS = R.CAMIS\n",
        "'''\n",
        "\n",
        "with engine.connect() as connection:\n",
        "\tinspections = pd.read_sql(text(sql), con=connection)"
      ],
      "metadata": {
        "id": "G65cQrAlZ5x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UR7tKEURPOu"
      },
      "source": [
        "# Pivot Tables\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple pivot tables\n",
        "\n",
        "[Pivot tables](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html) is one of the most commonly used exploratory tools, and in Pandas they are extremely flexible.\n",
        "\n",
        "In their simplest form, they can generate the same results as aggregate queries."
      ],
      "metadata": {
        "id": "yYkjSgvuqvt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rest_per_boro = pd.pivot_table(\n",
        "    data=restaurants,\n",
        "    aggfunc=\"count\",  # we count... (the aggregation function)\n",
        "    values=\"CAMIS\",  # ...the different CAMIS numbers (what we aggregate)\n",
        "    index=\"BORO\",  # ..per BORO (and how we specify the groups, ie the variable that we use for dividing the data)\n",
        ")\n"
      ],
      "metadata": {
        "id": "qlG17o_6bi0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The full pivot table\n",
        "rest_per_boro"
      ],
      "metadata": {
        "id": "i2ChiY2HcaFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or, let's try to examine the average inspection score, broken down by cuisine."
      ],
      "metadata": {
        "id": "cRaFEHAtb83S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_per_cuisine = pd.pivot_table(\n",
        "    data=inspections,\n",
        "    index=\"CUISINE_DESCRIPTION\",  # specifies the rows\n",
        "    values=\"SCORE\",  # specifies the content of the cells\n",
        "    aggfunc=\"mean\",  # we calculate the average/mean score\n",
        ")"
      ],
      "metadata": {
        "id": "ojdh6bstCh2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The full pivot table\n",
        "score_per_cuisine"
      ],
      "metadata": {
        "id": "zSaNEwxq_lOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the scores of the 10 highest scoring cuisines\n",
        "(\n",
        "    score_per_cuisine\n",
        "    .sort_values('SCORE') # sort in asceding order of score\n",
        "    .tail(10) # take the 10 entries in the largest values (at the botoom)\n",
        "    .plot(kind='barh') # create a horizontal bar plot / we use horizontal bar for better label readability\n",
        ")"
      ],
      "metadata": {
        "id": "0asooRX2CyGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "Show the average inspection score broken down by neighborhood code (the `NTA` variable)."
      ],
      "metadata": {
        "id": "ussGaj1gdAW5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ILJLwMc6dR1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pivot Tables and Dates"
      ],
      "metadata": {
        "id": "En8Fp4ATdSN4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5m48HZFRPOu"
      },
      "source": [
        "# Count the number of CAMIS values that appear on each date\n",
        "pivot = pd.pivot_table(\n",
        "    data=inspections,\n",
        "    index=\"INSPECTION_DATE\",  # specifies the rows\n",
        "    values=\"CAMIS\",  # specifies the content of the cells\n",
        "    aggfunc=\"count\",  # we ask to count how many different CAMIS values we see\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXbdJgt8RPOy"
      },
      "source": [
        "pivot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw_ySegDRPO0"
      },
      "source": [
        "Now, let's plot this. By default, Pandas considers the \"index\" column to be the x-axis, and plots the rest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcxPgXE6RPO9"
      },
      "source": [
        "pivot.plot(kind = 'line', y = 'CAMIS', figsize=(10, 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzK9tjhRPO_"
      },
      "source": [
        "# We keep the last 100 entries and plot\n",
        "pivot.tail(100).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Voat735yRPPZ"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Now let's do an exercise,  instead of counting the number of inspections, we want to compute the average score assigned by the inspectors. Hint: We will need to change the `values` and the `aggfunc` parameters in the `pivot_table` function above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlCG1ciIRPPa"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLgKXET5RPPb",
        "solution2": "hidden",
        "solution2_first": true
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As9qTwYLRPPb",
        "solution2": "hidden"
      },
      "source": [
        "pivot = pd.pivot_table(\n",
        "    data=inspections,\n",
        "    index=\"INSPECTION_DATE\",  # specifies the rows\n",
        "    values=\"SCORE\",  # specifies the content of the cells\n",
        "    aggfunc=\"mean\",  # compute the average SCORE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IidFXaRRPPc",
        "solution2": "hidden"
      },
      "source": [
        "pivot.plot(figsize=(10, 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JUwPHXWGLpiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuzOxstCRPPA"
      },
      "source": [
        "### Changing date granularity\n",
        "\n",
        "We can also use the [resample](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html) command to change the frequency from one day, to, say, 7 days. Then we can compute, say, the average (`mean()`) for these days, or the total number (`sum()`) of inspections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffCg-Jo-RPPB"
      },
      "source": [
        "pivot = pd.pivot_table(\n",
        "    data=inspections,\n",
        "    index=\"INSPECTION_DATE\",  # specifies the rows\n",
        "    values=\"CAMIS\",  # specifies the content of the cells\n",
        "    aggfunc=\"count\",  # we ask to count how many different CAMIS values we see\n",
        ")\n",
        "\n",
        "pivot.resample(\"1W\").sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B5xxo0gRPPC"
      },
      "source": [
        "Now, let's plot this. By default, Pandas considers the \"index\" column to be the x-axis, and plots the rest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDa0KRaqRPPC"
      },
      "source": [
        "# Plot the average number of inspections, over 7-day periods\n",
        "pivot.resample(\"1W\").sum().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4WKhTGLRPPF"
      },
      "source": [
        "# Plot the total number of inspections, over 1-month periods\n",
        "pivot.resample(\"1M\").sum().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_WH-s_DRPPK"
      },
      "source": [
        "plot = pivot.resample(\"7D\").mean().plot()\n",
        "plot.set_xlabel(\"Date of Inspection\")\n",
        "plot.set_ylabel(\"Average Number of Inspections (over a 7-day period)\")\n",
        "plot.set_title(\"Analysis of Number of Inspections over Time\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuhabll3RPPL"
      },
      "source": [
        "## Pivot Table with two (or more) variables\n",
        "\n",
        "We would like to break down the results by borough, so we add the `column` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x57cwCMARPPM"
      },
      "source": [
        "# Show grades broken down by borough\n",
        "pivot2 = pd.pivot_table(\n",
        "    data=inspections,  #\n",
        "    index=\"GRADE\",\n",
        "    columns=\"BORO\",\n",
        "    values=\"CAMIS\",\n",
        "    aggfunc=\"count\"\n",
        ")\n",
        "pivot2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMpy5ZOYRPPS"
      },
      "source": [
        "# By default, the \"index\" becomes the x-axis and we plot all numeric columns\n",
        "pivot2.plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS8nDH9DRPPW"
      },
      "source": [
        "## Advanced Pivot Tables\n",
        "\n",
        "We can also add multiple attributes in the index and columns. It is also possible to have multiple aggregation functions, and we can even define our own aggregation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX1uJBmsRPPW"
      },
      "source": [
        "# We break down by BORO and GRADE, and also calculate\n",
        "# inspections scores\n",
        "pivot_advanced = pd.pivot_table(\n",
        "    data=inspections,  #\n",
        "    index=\"INSPECTION_DATE\",\n",
        "    columns=[\"BORO\", \"GRADE\"],\n",
        "    values=\"SCORE\",\n",
        "    aggfunc=[\"mean\", \"std\"],\n",
        ")\n",
        "\n",
        "# Take the total number of inspections (unique and non-unique)\n",
        "agg = pivot_advanced.resample(\"1M\").mean()\n",
        "\n",
        "# Show the last 5 entries and show the transpose (.T)\n",
        "agg.tail().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalization, with application to Pivot Tables (and beyond)"
      ],
      "metadata": {
        "id": "G7ILoF2jwAXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's say that we want to normalize the values\n",
        "# to account for the different number of inspections\n",
        "# in each borough\n",
        "pivot2.sum()"
      ],
      "metadata": {
        "id": "CBK2AWNAvIVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This command normalizes each column, by dividing with its sum:\n",
        "pivot2 / pivot2.sum()"
      ],
      "metadata": {
        "id": "8-rMTEBrvpvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_by_borough = pivot2 / pivot2.sum()\n",
        "\n",
        "# Percent of inspections per borough with a given grade\n",
        "normalized_by_borough.plot(kind='bar')"
      ],
      "metadata": {
        "id": "B-ZMwlyqvxxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalization and Transpose"
      ],
      "metadata": {
        "id": "iTNXe4lYv90l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This takes the transpose of the dataframe\n",
        "pivot2.T"
      ],
      "metadata": {
        "id": "EilqcAPnycVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the transpose now uses the boroughs as the \"x\" axis\n",
        "pivot2.T.plot(kind='barh')"
      ],
      "metadata": {
        "id": "l2888zb6rOlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variation,\n",
        "pivot2.T.plot(kind='barh', stacked=True)"
      ],
      "metadata": {
        "id": "z191SUr7wnQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_by_borough.T.plot(kind='barh', stacked=True).legend(frameon=True)"
      ],
      "metadata": {
        "id": "0cCgPPlnwNsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Exercise\n",
        "\n",
        "We now want to examine if different cuisines have different inspection scores. Compute the average inspection score by cuisine. Use the `sort_values()` command ([documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html)) to order cuisines by their inspection scores. Analyze further by breaking down the score over inspection dates, and plot."
      ],
      "metadata": {
        "id": "zH7HoWXO9sbj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zGzg60Fo9uv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Solution"
      ],
      "metadata": {
        "id": "iOK_LNF-9zkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "popular = (\n",
        "    pd.pivot_table(\n",
        "    data=inspections,\n",
        "    index=\"CUISINE_DESCRIPTION\",  # cuisines are the rows\n",
        "    values=\"SCORE\",  # we analyze the SCORE\n",
        "    aggfunc=[\"mean\",\"count\"]  # compute the average SCORE\n",
        "    )\n",
        "    .sort_values(by=('count','SCORE'), ascending=False) # sort according to the popularity (count) of each cuisine\n",
        "    .head(4) # keep the top-4 most popular cuisined\n",
        "    .index # keep the names of the cuisines, which appear in the index\n",
        "    .values # and retrieve their values\n",
        ")"
      ],
      "metadata": {
        "id": "yTxLj1Cno2PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select 3 columns (american, frenchn, chinese), compute the average score for a month\n",
        "# and plot the results\n",
        "(\n",
        "    pd.pivot_table(\n",
        "        data=inspections,\n",
        "        index=\"INSPECTION_DATE\",  # dates are the rows\n",
        "        columns=\"CUISINE_DESCRIPTION\",  # cuisines are the columns\n",
        "        values=\"SCORE\",  # we analyze the SCORE\n",
        "        aggfunc=\"mean\"  # compute the average SCORE\n",
        "    )\n",
        "    .filter(popular) # keep only the popular cuisines\n",
        "    .resample(\"3M\").mean() # convert granularity to monthly and taking average score\n",
        "    .reset_index() # we take the INSPECTION_DATE out of the index to query and limit the x-axis\n",
        "    .query(\"INSPECTION_DATE > '2021-01-01' \") # keep only dates after 2001\n",
        "    .plot(\n",
        "        kind = 'line',\n",
        "        marker = 'o', markersize = 5, linewidth = 1,\n",
        "        x = \"INSPECTION_DATE\",\n",
        "        y = popular,\n",
        "        figsize=(15, 4),\n",
        "        title = \"Average Score by Cuisine over Time\"\n",
        "      ).legend(\n",
        "          loc='upper left',\n",
        "      )\n",
        ")"
      ],
      "metadata": {
        "id": "5qKvSZ6Z90ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv0aU9yQRPPh"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV9NGwc2bUCS"
      },
      "source": [
        "# Defining new columns -- `assign()` and `apply()`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdiZXyXIq4rx"
      },
      "source": [
        "### Using the `assign()` approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlTXmZwqkcSE"
      },
      "source": [
        "The `assign` command applies a function to a dataframe and returns back a new dataframe with the new column(s)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We define functions that take as input a dataframe df\n",
        "# and return back a new column.\n",
        "\n",
        "# This function combines STREET/BUILDING/BORO/ZIPCODE columns into one address\n",
        "#\n",
        "def combine_address(df):\n",
        "  return (df.BUILDING + ' ' + df.STREET + ', ' + df.BORO + ', NY ' + df.ZIPCODE).str.upper()\n",
        "\n",
        "\n",
        "# This function computes the distance (in miles) from NYU,\n",
        "# given the lat/lon of the other location\n",
        "#\n",
        "def distance(df):\n",
        "  NYU_lon = -73.9962293\n",
        "  NYU_lat = 40.7291527\n",
        "  # The calculation below is simply the Pythagorean theorem.\n",
        "  # The normalizing values \"0.0146\" and \"0.0196\"\n",
        "  # are just for converting lat/lon differences to miles\n",
        "  distance = ((df['LATITUDE']-NYU_lat)/0.0146)**2 + ((df['LONGITUDE']-NYU_lon)/0.0196)**2\n",
        "  return np.sqrt(distance)\n",
        "\n"
      ],
      "metadata": {
        "id": "D3NMDMFu6cpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqr1oIJYczP3"
      },
      "source": [
        "# We now use the `assign` function to create two new columns\n",
        "# using the logic in the functions above,\n",
        "(\n",
        "  restaurants\n",
        "  .assign(\n",
        "      distance_from_NYU = distance,\n",
        "      address = combine_address\n",
        "  )\n",
        "  .filter(items = ['DBA','address','distance_from_NYU'])\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ub8-qFWixeb"
      },
      "source": [
        "# And let's eliminate now duplicates and sort by distance\n",
        "(\n",
        "  restaurants\n",
        "  .assign(\n",
        "      distance_from_NYU = distance,\n",
        "      address = combine_address\n",
        "  )\n",
        "  .filter(items = ['DBA','address','distance_from_NYU'])\n",
        "  .query('distance_from_NYU > 0') # eliminates NaN values from distance_from_NYU\n",
        "  .drop_duplicates()\n",
        "  .sort_values('distance_from_NYU')\n",
        "  .head(25)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgr0Yg_3k6qW"
      },
      "source": [
        "### Using the `apply` approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njW0EhjzmyK6"
      },
      "source": [
        "The `apply` function allow the users to pass a function and apply it on every single row or column of a Pandas datarame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIZ_H-s6db9e"
      },
      "source": [
        "!sudo pip3 install -q -U geopy\n",
        "\n",
        "from geopy import distance\n",
        "\n",
        "# A bit more accurate distance calculation, which returns back\n",
        "# the distance in miles. However, we cannot pass a dataframe\n",
        "# to the function but only individual values\n",
        "def distance_from_NYU_geodesic(row):\n",
        "  NYU_lon = -73.9962293\n",
        "  NYU_lat = 40.7291527\n",
        "  NYU = (NYU_lat, NYU_lon)\n",
        "  rest = (row.LATITUDE, row.LONGITUDE)\n",
        "  #if pd.isnull(row.Latitude) or pd.isnull(row.Longitude):\n",
        "  #  return None\n",
        "  return distance.distance(NYU, rest).miles\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71KKNBOqlBTp"
      },
      "source": [
        "# We now create a smaller version of the dataset with just\n",
        "# the names/address/lon/lat of the restaurants\n",
        "rest_names_locations = (\n",
        "    restaurants\n",
        "    .assign(\n",
        "      address = combine_address\n",
        "    )\n",
        "    .filter(items = ['CAMIS','DBA','address','LONGITUDE', 'LATITUDE'])\n",
        "    .query(' LONGITUDE==LONGITUDE ') # idiomatic expression for saying IS NOT NULL\n",
        "    .query(' LATITUDE==LATITUDE ') # idiomatic expression for saying IS NOT NULL\n",
        "    .drop_duplicates()\n",
        ")\n",
        "\n",
        "rest_names_locations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q0gGzxOpE7x"
      },
      "source": [
        "# We will now apply the function distance_from_NYU_geodesic\n",
        "# to every row of the dataset:\n",
        "rest_names_locations.apply(distance_from_NYU_geodesic, axis='columns')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82MvcB29pG1z"
      },
      "source": [
        "# We will now save the result into a new column\n",
        "rest_names_locations['distance_from_NYU']=rest_names_locations.apply(distance_from_NYU_geodesic, axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6vbuAUfdglf"
      },
      "source": [
        "# Let's see how many restaurants are within half a mile from NYU :)\n",
        "(\n",
        "    rest_names_locations\n",
        "    .query('distance_from_NYU < 0.5')\n",
        "    .sort_values('distance_from_NYU')\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54FqcwHSeUM7"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further dataset exploration\n",
        "\n",
        "## Restaurant Risk Assessment\n",
        "\n",
        "* Which restaurants or restaurant chains have a history of repeated, high-scoring violations?\n",
        "* Can we identify patterns in violation types or frequencies based on cuisine type, location?\n",
        "\n",
        "## Geographic Analysis of Violations\n",
        "\n",
        "* Are there specific neighborhoods (NTAs) or zip codes that have a higher prevalence of certain violation types (e.g., pest-related violations)?\n",
        "* How does the average inspection score vary across different boroughs?\n",
        "Visualize the distribution of restaurants and their inspection scores on a map of NYC.\n",
        "\n",
        "## Temporal Analysis of Inspections\n",
        "\n",
        "* How have violation types changed over time?\n",
        "Are there seasonal trends in certain violation types?\n",
        "* What is the average time between inspections for restaurants?\n",
        "\n",
        "## Restaurant Chain Performance\n",
        "\n",
        "* How do major restaurant chains compare in terms of average inspection scores and violation rates?\n",
        "* Are there specific chains that consistently perform better or worse than average?\n",
        "* Analyze the relationship between the number of locations a chain has and its average inspection score.\n",
        "\n"
      ],
      "metadata": {
        "id": "-kpmrvrxuI85"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjG4WrB5RPPj",
        "solution2": "hidden"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}