{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with the IBM Watson Natural Language Understanding API; POST vs GET\n",
    "\n",
    "Another useful API, especially when dealing with text, is the [IBM Watson  Natural Language Understanding API](https://console.bluemix.net/catalog/services/natural-language-understanding), which offers a variety of text analysis functionalities, such as sentiment analysis, entity extraction, keyword extraction, etc.\n",
    "\n",
    "We will give a couple of examples below, to understand how we can take an unstructured piece of text (either the text alone, or a URL with text), and extract some \"semi-structured\" representation of its content.\n",
    "\n",
    "\n",
    "\n",
    "## /analyze call\n",
    "\n",
    "We will first start with the `GET /analyze` API call ([documentation](https://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/#get-analyze)), which takes as input a piece of text, and returns an analysis across various dimensions.\n",
    "\n",
    "The call below gets as input a \"text\" variable, and returns back the sentiment of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def getSentiment(text):\n",
    "    endpoint = \"https://gateway.watsonplatform.net/natural-language-understanding/api/v1/analyze\"\n",
    "\n",
    "    # You can register and get your own credentials\n",
    "    # The ones below have a quota of 1000 calls per day \n",
    "    # and can run out quickly if multiple people use these\n",
    "    username = \"apikey\"\n",
    "    password = \"xSOLcYbCwXT5bRS36huaiwO9kO07_m1EaMa769hTMpcR\"\n",
    "    \n",
    "    parameters = {\n",
    "        'features': 'emotion,sentiment',\n",
    "        'version' : '2018-11-16',\n",
    "        'text': text,\n",
    "        'language' : 'en',\n",
    "        # url = url_to_analyze, this is an alternative to sending the text\n",
    "    }\n",
    "\n",
    "    resp = requests.get(endpoint, params=parameters, auth=(username, password))\n",
    "    \n",
    "    return resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will analyze the text below using the IBM Watson API\n",
    "\n",
    "text = '''\n",
    "I got their Egg & Cheese sandwich on a Whole Wheat Everything Bagel. \n",
    "First off, I loved loved loved the texture of the bagel itself. \n",
    "It was very chewy yet soft, which is a top feature for a NY style bagel. \n",
    "However, I thought there could've been more seasoning on top of \n",
    "the bagel as I found the bagel itself to be a bit bland. \n",
    "\n",
    "Speaking of bland, I thought the egg and cheese filling were also quite bland. \n",
    "This was definitely lacking salt and pepper in the eggs and the cheese didn't\n",
    "really add too much flavor either, which was really disappointing! \n",
    "My mom also had the same complaint with her bagel sandwich \n",
    "(she had the egg sandwich on a blueberry bagel) so I definitely wasn't \n",
    "the only one.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getSentiment(text)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to understand the structure of the answer. First, we check the high-level keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check the content of these keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go deeper into the 'emotion' dictionary\n",
    "data['emotion']['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And a bit more\n",
    "data['emotion']['document']['emotion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Type your own piece of text, and analyze it to extract sentiment and emotions. Discuss your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities call\n",
    "\n",
    "[Full Documentation of the call](https://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/#entities)\n",
    "\n",
    "This is a an API call that extracts entities from the text, and also the sentiment and emotion for each of these entities.\n",
    "\n",
    "There are two new technical aspects with this API. First of all, we use the command `requests.post` as opposed to `requests.get`. This happens because `GET` is designed to handle limited amount of data. When we have a large volume of data to send as parameters, then the HTTP protocol requires the use of the `POST` command. You will also see that the parameters that we pass are not \"flat\" as they used to be. Instead we submit the `watson_options` as the set of parameters, which is itself semi-structured.\n",
    "\n",
    "In terms of natural language processing, we will examine a couple of capabilities of the API. First, you will see that there is the capability of \"normalizing\" each entity, so that two different ways of saying the same thing get mapped to the same entity. So for example, \"President Trump\" and \"Donald Trump\" get mapped to the same Knowledge Graph entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def processURL(url_to_analyze):\n",
    "    endpoint_watson = \"https://gateway.watsonplatform.net/natural-language-understanding/api/v1/analyze\"\n",
    "    params = {\n",
    "        'version': '2018-11-16',\n",
    "    }\n",
    "    headers = { \n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "    watson_options = {\n",
    "      \"url\": url_to_analyze,\n",
    "      \"features\": {\n",
    "        \"entities\": {\n",
    "          \"sentiment\": True,\n",
    "          \"emotion\": True,\n",
    "          \"limit\": 10\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    username = \"apikey\"\n",
    "    password = \"xSOLcYbCwXT5bRS36huaiwO9kO07_m1EaMa769hTMpcR\"\n",
    "\n",
    "    resp = requests.post(endpoint_watson, \n",
    "                         data=json.dumps(watson_options), \n",
    "                         headers=headers, \n",
    "                         params=params, \n",
    "                         auth=(username, password) \n",
    "                        )\n",
    "    return resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_analyze = 'https://www.cnn.com/2019/06/20/politics/drone-shot-down-by-iran-airspace-dispute-explainer/index.html'\n",
    "\n",
    "data = processURL(url_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what we get back as top-level attributes\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let' see the entities list\n",
    "data[\"entities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let' see the first entity. Notice the \"disambiguated\" attribute that\n",
    "# points to \"canonical\" versions of the entity, in DBPedia, Freebase, OpenCYC, YAGO, etc\n",
    "data[\"entities\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes as input the result\n",
    "# from the IBM Watson API and returns a list\n",
    "# of entities that are relevant (above threshold)\n",
    "# to the article\n",
    "def getEntities(data, threshold):\n",
    "    result = []\n",
    "    for entity in data[\"entities\"]:\n",
    "        relevance = float(entity['relevance'])\n",
    "        if relevance > threshold:\n",
    "            result.append(entity['text'])\n",
    "    return result\n",
    "\n",
    "getEntities(data, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "* First of all, **get your own credentials for the IBM Watson API**. The demo key that we use above has a limited quota.\n",
    "* Use an API to get news articles. \n",
    "    * Option 1: Use the API at https://newsapi.org to fetch the news from various sources. Print the entities that are currently being discussed in the news, together with their relevance value and the associated sentiment.\n",
    "    * Option 2: Use the NY Times API to fetch the Top Stories News. You can register and get an API key at https://developer.nytimes.com/. The `Top Stories V2 API` provides the details of the news of the day: (The API call documentation is at https://developer.nytimes.com/top_stories_v2.json and the API Call is  https://api.nytimes.com/svc/topstories/v2/home.json?api-key=PUTYOURKEYHERE). Repeat the entity extraction process from above.\n",
    "    * Option 3: Use the Guardian API at https://open-platform.theguardian.com/documentation/ to fetch news from The Guardian.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
